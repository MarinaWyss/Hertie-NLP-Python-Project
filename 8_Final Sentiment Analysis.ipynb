{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.dates import DateFormatter\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis:\n",
    "    \"\"\"\n",
    "    A class to runs a TextBlob sentiment analysis and create descriptive plots.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._sentence_data = None\n",
    "        self.clean_data = None\n",
    "        self._sentiment_analysis = None\n",
    "        self.candidate_sentiment = None\n",
    "        self.sanders_sentiment_plot = None\n",
    "        self.biden_sentiment_plot = None\n",
    "        self.sentiment_time = None\n",
    "        self.sentiment_time_plot = None\n",
    "    \n",
    "    def sentence_data(self):\n",
    "        \"\"\"\n",
    "        Reads in sentence data from scraper and removes punctuation, numbers, stopwords and lowercases from sentence data and adds to new column in data.\n",
    "        return: pd.DataFrame\n",
    "        \"\"\"\n",
    "        self.sentence_data = pd.read_csv('data/sentence_data.csv')\n",
    "        \n",
    "        # setup\n",
    "        sentences = self.sentence_data['article_text']\n",
    "\n",
    "        # lowercase everything\n",
    "        sentences = [sentences.lower() for sentences in sentences]\n",
    "\n",
    "        # remove punctuation\n",
    "        sentences = [s.replace(\"’s\",'') for s in sentences] # remove apostrophe s first\n",
    "        sentences = [re.sub(r'[^\\w\\s]','',s) for s in sentences]\n",
    "\n",
    "        # remove numbers\n",
    "        sentences = [re.sub('[0-9]','', s) for s in sentences]\n",
    "\n",
    "        # remove double space\n",
    "        sentences = [s.replace(\"  \",' ') for s in sentences]\n",
    "\n",
    "        # remove stopwords\n",
    "        clean = []\n",
    "        for item in sentences:\n",
    "            for word in stopwords.words('english'):\n",
    "                item = item.replace(\" \" + word + \" \", ' ')\n",
    "            clean.append(item)\n",
    "\n",
    "        self.sentence_data['article_text_clean'] = clean\n",
    "        \n",
    "        return self.sentence_data\n",
    "    \n",
    "    def sentiment_analysis(self):\n",
    "        \"\"\"\n",
    "        Uses TextBlob's rule-based API to conduct sentiment analysis. Adds score to new column in data.\n",
    "        return: pd.DataFrame\n",
    "        \"\"\"\n",
    "        # setup\n",
    "        data = self.sentence_data\n",
    "        text = self.sentence_data['article_text_clean']\n",
    "        score = []\n",
    "        \n",
    "        for sentence in text:\n",
    "            sentence = TextBlob(sentence)\n",
    "            x = sentence.sentiment\n",
    "            x = sentence.sentiment.polarity\n",
    "            score.append(x)\n",
    "\n",
    "        data['score'] = score\n",
    "\n",
    "        # Convert float score to category based on binning to get 5 levels\n",
    "        data['sentiment'] = pd.cut(data['score'],\n",
    "                            bins=5,\n",
    "                            labels=[1, 2, 3, 4, 5])\n",
    "        data['sentiment'] = pd.to_numeric(data['sentiment'])\n",
    "        data = data.drop('score', axis=1)\n",
    "        \n",
    "        self.sentiment_analysis = data\n",
    "        \n",
    "        return self.sentiment_analysis\n",
    "\n",
    "    def candidate_sentiment_means(self):\n",
    "        \"\"\"\n",
    "        Calculates the sentiment averages accross all candidates, per candidate and per candidate and outlet.\n",
    "        return: dataframe of candidate sentiment mean\n",
    "        \"\"\"\n",
    "        data = self.sentiment_analysis\n",
    "        \n",
    "        #sanders\n",
    "        sanders = data.loc[data['Sanders'] == 1]\n",
    "        sanders_sent_mean = sanders['sentiment'].mean()\n",
    "        sanders_sentiment = sanders.groupby('publisher')['sentiment'].mean().reset_index()\n",
    "\n",
    "        #biden\n",
    "        biden = data.loc[data['Biden'] == 1]\n",
    "        biden_sent_mean = biden['sentiment'].mean()\n",
    "        biden_sentiment = biden.groupby('publisher')['sentiment'].mean().reset_index()\n",
    "        \n",
    "        # total average\n",
    "        combined = pd.concat([sanders, biden], axis=0)\n",
    "        sent_mean = data['sentiment'].mean()\n",
    "        \n",
    "        self.candidate_sentiment_means = pd.DataFrame(data={'sent_mean': [sent_mean],\n",
    "                                                            'sanders_sent_mean': [sanders_sent_mean],\n",
    "                                                            'biden_sent_mean': [biden_sent_mean]})\n",
    "        return self.candidate_sentiment_means\n",
    "\n",
    "    def sentiment_time_plot(self):\n",
    "        \"\"\"\n",
    "        Plots sentiment scores per candidate over time\n",
    "        return: bar plot\n",
    "        \"\"\"\n",
    "        warnings.simplefilter(action='ignore')\n",
    "        \n",
    "        data = self.sentiment_analysis\n",
    "\n",
    "        # filter sentences only about one candidate\n",
    "        sanders = data.loc[data['Sanders'] == 1]\n",
    "        biden = data.loc[data['Biden'] == 1]      \n",
    "        combined = pd.concat([sanders, biden], axis=0)\n",
    "\n",
    "        #candidate_sentiment = data.loc[data['candidates_mentioned'] == 1]\n",
    "        candidate_sentiment = combined\n",
    "\n",
    "        candidates = ['Sanders', 'Biden']\n",
    "        # create new column with candidate name\n",
    "        candidate_sentiment['candidate'] = candidate_sentiment['article_text'].str.extract('({})'.format('|'.join(candidates)),\n",
    "                                                    flags = re.IGNORECASE, expand = False).str.lower().fillna('')\n",
    "        candidate_sentiment['candidate'] = np.where(candidate_sentiment['article_text'].str.contains('bernie'), 'sanders', candidate_sentiment['candidate'])\n",
    "        candidate_sentiment = candidate_sentiment[['date', 'sentiment', 'candidate']]\n",
    "        candidate_sentiment = candidate_sentiment[candidate_sentiment.candidate != '']\n",
    "\n",
    "        # make dates consistent and filter for time frame\n",
    "        candidate_sentiment['date'] = pd.to_datetime(candidate_sentiment['date'], errors='coerce')\n",
    "        mask = (candidate_sentiment['date'].astype('str') >= \"2020-03-01\") & (candidate_sentiment['date'].astype('str') < \"2020-04-19\")\n",
    "        candidate_sentiment = candidate_sentiment.loc[mask]\n",
    "\n",
    "        # mean sentiment per day\n",
    "        mean_per_day = candidate_sentiment.groupby(['date', 'candidate']).mean()\n",
    "        mean_per_day.reset_index(inplace = True)\n",
    "\n",
    "        chart = sns.lineplot(x = 'date', y = 'sentiment', hue = 'candidate', palette=\"PuBu\", data = mean_per_day)\n",
    "        plt.setp(chart.get_xticklabels(), rotation = 45)\n",
    "        plt.setp(chart.get_xticklabels(), rotation = 45)\n",
    "        plt.title('Average Sentiment Over Time')\n",
    "        plt.title('Average Sentiment Over Time')\n",
    "        chart.legend(loc='center right', bbox_to_anchor=(1.3, 0.5), ncol=1)\n",
    "        plt.savefig('sentiment_time.png', bbox_inches='tight')\n",
    "            \n",
    "    def sanders_sentiment_plot(self):\n",
    "        \"\"\"\n",
    "        Plots difference in Sander's sentiment average per publisher to his overall sentiment mean.\n",
    "        return: bar plot\n",
    "        \"\"\"\n",
    "        data = self.sentiment_analysis\n",
    "        \n",
    "        sanders = data.loc[data['Sanders'] == 1]\n",
    "\n",
    "        # AP sentiment\n",
    "        AP = sanders.loc[sanders['publisher'] == \"AP\"]\n",
    "        AP_sent = AP['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        AP_sent_count = AP_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        AP_1 = AP_sent_count[1]/len(AP_sent)\n",
    "        AP_2 = AP_sent_count[2]/len(AP_sent)\n",
    "        AP_3 = AP_sent_count[3]/len(AP_sent)\n",
    "        AP_4 = AP_sent_count[4]/len(AP_sent)\n",
    "        AP_5 = AP_sent_count[5]/len(AP_sent)\n",
    "\n",
    "        # Breitbart sentiment\n",
    "        Breitbart = sanders.loc[sanders['publisher'] == \"Breitbart\"]\n",
    "        Breitbart_sent = Breitbart['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        Breitbart_sent_count = Breitbart_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        Breitbart_1 = Breitbart_sent_count[1]/len(Breitbart_sent)\n",
    "        Breitbart_2 = Breitbart_sent_count[2]/len(Breitbart_sent)\n",
    "        Breitbart_3 = Breitbart_sent_count[3]/len(Breitbart_sent)\n",
    "        Breitbart_4 = Breitbart_sent_count[4]/len(Breitbart_sent)\n",
    "        Breitbart_5 = Breitbart_sent_count[5]/len(Breitbart_sent)\n",
    "\n",
    "        # Fox sentiment\n",
    "        Fox = sanders.loc[sanders['publisher'] == \"Fox\"]\n",
    "        Fox_sent = Fox['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        Fox_sent_count = Fox_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        Fox_1 = Fox_sent_count[1]/len(Fox_sent)\n",
    "        Fox_2 = Fox_sent_count[2]/len(Fox_sent)\n",
    "        Fox_3 = Fox_sent_count[3]/len(Fox_sent)\n",
    "        Fox_4 = Fox_sent_count[4]/len(Fox_sent)\n",
    "        Fox_5 = Fox_sent_count[5]/len(Fox_sent)\n",
    "\n",
    "        # Buzzfeed sentiment\n",
    "        buzzfeed = sanders.loc[sanders['publisher'] == \"buzzfeed\"]\n",
    "        buzzfeed_sent = buzzfeed['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        buzzfeed_sent_count = buzzfeed_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        buzzfeed_1 = buzzfeed_sent_count[1]/len(buzzfeed_sent)\n",
    "        buzzfeed_2 = buzzfeed_sent_count[2]/len(buzzfeed_sent)\n",
    "        buzzfeed_3 = buzzfeed_sent_count[3]/len(buzzfeed_sent)\n",
    "        buzzfeed_4 = buzzfeed_sent_count[4]/len(buzzfeed_sent)\n",
    "        buzzfeed_5 = buzzfeed_sent_count[5]/len(buzzfeed_sent)\n",
    "\n",
    "        # NBC\n",
    "        nbc = sanders.loc[sanders['publisher'] == \"nbc\"]\n",
    "        nbc_sent = nbc['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        nbc_sent_count = nbc_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        nbc_1 = nbc_sent_count[1]/len(nbc_sent)\n",
    "        nbc_2 = nbc_sent_count[2]/len(nbc_sent)\n",
    "        nbc_3 = nbc_sent_count[3]/len(nbc_sent)\n",
    "        nbc_4 = nbc_sent_count[4]/len(nbc_sent)\n",
    "        nbc_5 = nbc_sent_count[5]/len(nbc_sent)\n",
    "\n",
    "        # New York Times\n",
    "        new_york_times = sanders.loc[sanders['publisher'] == \"new_york_times\"]\n",
    "        new_york_times_sent = new_york_times['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        new_york_times_sent_count = new_york_times_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        new_york_times_1 = new_york_times_sent_count[1]/len(new_york_times_sent)\n",
    "        new_york_times_2 = new_york_times_sent_count[2]/len(new_york_times_sent)\n",
    "        new_york_times_3 = new_york_times_sent_count[3]/len(new_york_times_sent)\n",
    "        new_york_times_4 = new_york_times_sent_count[4]/len(new_york_times_sent)\n",
    "        new_york_times_5 = new_york_times_sent_count[5]/len(new_york_times_sent)\n",
    "\n",
    "        # Politico\n",
    "        politico = sanders.loc[sanders['publisher'] == \"politico\"]\n",
    "        politico_sent = politico['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        politico_sent_count = politico_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        politico_1 = politico_sent_count[1]/len(politico_sent)\n",
    "        politico_2 = politico_sent_count[2]/len(politico_sent)\n",
    "        politico_3 = politico_sent_count[3]/len(politico_sent)\n",
    "        politico_4 = politico_sent_count[4]/len(politico_sent)\n",
    "        politico_5 = politico_sent_count[5]/len(politico_sent)\n",
    "\n",
    "        # Washington Times\n",
    "        washington_times = sanders.loc[sanders['publisher'] == \"washington_times\"]\n",
    "        washington_times_sent = washington_times['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        washington_times_sent_count = washington_times_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        washington_times_1 = washington_times_sent_count[1]/len(washington_times_sent)\n",
    "        washington_times_2 = washington_times_sent_count[2]/len(washington_times_sent)\n",
    "        washington_times_3 = washington_times_sent_count[3]/len(washington_times_sent)\n",
    "        washington_times_4 = washington_times_sent_count[4]/len(washington_times_sent)\n",
    "        washington_times_5 = washington_times_sent_count[5]/len(washington_times_sent)\n",
    "        \n",
    "        #setup plot\n",
    "        category_names = ['Extremely negative', 'Negative','Neutral', 'Positive', 'Extremely positive']\n",
    "        publishers = {\n",
    "            'AP': [AP_1, AP_2, AP_3, AP_4, AP_5],\n",
    "            'Breitbart': [Breitbart_1, Breitbart_2, Breitbart_3, Breitbart_4, Breitbart_5],\n",
    "            'Fox': [Fox_1, Fox_2, Fox_3, Fox_4, Fox_5],\n",
    "            'Buzzfeed': [buzzfeed_1, buzzfeed_2, buzzfeed_3, buzzfeed_4, buzzfeed_5],\n",
    "            'NBC': [nbc_1, nbc_2, nbc_3, nbc_4, nbc_5],\n",
    "            'New York Times': [new_york_times_1, new_york_times_2, new_york_times_3, new_york_times_4, new_york_times_5],\n",
    "            'Politico': [politico_1, politico_2, politico_3, politico_4, politico_5],\n",
    "            'Washington Times': [washington_times_1, washington_times_2, washington_times_3, washington_times_4, washington_times_5]\n",
    "        }\n",
    "\n",
    "        def survey(publishers, category_names):\n",
    "            labels = list(publishers.keys())\n",
    "            data = np.array(list(publishers.values()))\n",
    "            data_cum = data.cumsum(axis=1)\n",
    "            category_colors = plt.get_cmap('RdYlGn')(\n",
    "                np.linspace(0.15, 0.85, data.shape[1]))\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            ax.invert_yaxis()\n",
    "            ax.xaxis.set_visible(False)\n",
    "            ax.set_xlim(0, np.sum(data, axis=1).max())\n",
    "\n",
    "            for i, (colname, color) in enumerate(zip(category_names, category_colors)):\n",
    "                widths = data[:, i]\n",
    "                starts = data_cum[:, i] - widths\n",
    "                ax.barh(labels, widths, left=starts, height=0.5,\n",
    "                        label=colname, color=color)\n",
    "                xcenters = starts + widths / 2\n",
    "\n",
    "                r, g, b, _ = color\n",
    "                text_color = 'white' if r * g * b < 0.5 else 'darkgrey'\n",
    "                for y, (x, c) in enumerate(zip(xcenters, widths)):\n",
    "                    ax.text(x, y, str(\"{0:.0%}\".format(c)), ha='center', va='center',\n",
    "                            color=text_color)\n",
    "            ax.legend(ncol=len(category_names), bbox_to_anchor=(0, 1),\n",
    "                      loc='lower left', fontsize='small')\n",
    "\n",
    "            return fig, ax\n",
    "\n",
    "        survey(publishers, category_names)\n",
    "        plt.savefig('sentiment_count_sanders.png', bbox_inches='tight')     \n",
    "        \n",
    "    def biden_sentiment_plot(self):\n",
    "        \"\"\"\n",
    "        Plots Biden's sentiment breakdown per publisher.\n",
    "        return: bar plot\n",
    "        \"\"\"\n",
    "        data = self.sentiment_analysis\n",
    "        \n",
    "        biden = data.loc[data['Biden'] == 1]\n",
    "        \n",
    "        # AP sentiment\n",
    "        AP = biden.loc[biden['publisher'] == \"AP\"]\n",
    "        AP_sent = AP['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        AP_sent_count = AP_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        AP_1 = AP_sent_count[1]/len(AP_sent)\n",
    "        AP_2 = AP_sent_count[2]/len(AP_sent)\n",
    "        AP_3 = AP_sent_count[3]/len(AP_sent)\n",
    "        AP_4 = AP_sent_count[4]/len(AP_sent)\n",
    "        AP_5 = AP_sent_count[5]/len(AP_sent)\n",
    "\n",
    "        # Breitbart sentiment\n",
    "        Breitbart = biden.loc[biden['publisher'] == \"Breitbart\"]\n",
    "        Breitbart_sent = Breitbart['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        Breitbart_sent_count = Breitbart_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        Breitbart_1 = Breitbart_sent_count[1]/len(Breitbart_sent)\n",
    "        Breitbart_2 = Breitbart_sent_count[2]/len(Breitbart_sent)\n",
    "        Breitbart_3 = Breitbart_sent_count[3]/len(Breitbart_sent)\n",
    "        Breitbart_4 = Breitbart_sent_count[4]/len(Breitbart_sent)\n",
    "        Breitbart_5 = Breitbart_sent_count[5]/len(Breitbart_sent)\n",
    "\n",
    "        # Fox sentiment\n",
    "        Fox = biden.loc[biden['publisher'] == \"Fox\"]\n",
    "        Fox_sent = Fox['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        Fox_sent_count = Fox_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        Fox_1 = Fox_sent_count[1]/len(Fox_sent)\n",
    "        Fox_2 = Fox_sent_count[2]/len(Fox_sent)\n",
    "        Fox_3 = Fox_sent_count[3]/len(Fox_sent)\n",
    "        Fox_4 = Fox_sent_count[4]/len(Fox_sent)\n",
    "        Fox_5 = Fox_sent_count[5]/len(Fox_sent)\n",
    "\n",
    "        # Buzzfeed sentiment\n",
    "        buzzfeed = biden.loc[biden['publisher'] == \"buzzfeed\"]\n",
    "        buzzfeed_sent = buzzfeed['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        buzzfeed_sent_count = buzzfeed_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        buzzfeed_1 = buzzfeed_sent_count[1]/len(buzzfeed_sent)\n",
    "        buzzfeed_2 = buzzfeed_sent_count[2]/len(buzzfeed_sent)\n",
    "        buzzfeed_3 = buzzfeed_sent_count[3]/len(buzzfeed_sent)\n",
    "        buzzfeed_4 = buzzfeed_sent_count[4]/len(buzzfeed_sent)\n",
    "        buzzfeed_5 = buzzfeed_sent_count[5]/len(buzzfeed_sent)\n",
    "\n",
    "        # NBC\n",
    "        nbc = biden.loc[biden['publisher'] == \"nbc\"]\n",
    "        nbc_sent = nbc['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        nbc_sent_count = nbc_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        nbc_1 = nbc_sent_count[1]/len(nbc_sent)\n",
    "        nbc_2 = nbc_sent_count[2]/len(nbc_sent)\n",
    "        nbc_3 = nbc_sent_count[3]/len(nbc_sent)\n",
    "        nbc_4 = nbc_sent_count[4]/len(nbc_sent)\n",
    "        nbc_5 = nbc_sent_count[5]/len(nbc_sent)\n",
    "\n",
    "        # New York Times\n",
    "        new_york_times = biden.loc[biden['publisher'] == \"new_york_times\"]\n",
    "        new_york_times_sent = new_york_times['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        new_york_times_sent_count = new_york_times_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        new_york_times_1 = new_york_times_sent_count[1]/len(new_york_times_sent)\n",
    "        new_york_times_2 = new_york_times_sent_count[2]/len(new_york_times_sent)\n",
    "        new_york_times_3 = new_york_times_sent_count[3]/len(new_york_times_sent)\n",
    "        new_york_times_4 = new_york_times_sent_count[4]/len(new_york_times_sent)\n",
    "        new_york_times_5 = new_york_times_sent_count[5]/len(new_york_times_sent)\n",
    "\n",
    "        # Politico\n",
    "        politico = biden.loc[biden['publisher'] == \"politico\"]\n",
    "        politico_sent = politico['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        politico_sent_count = politico_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        politico_1 = politico_sent_count[1]/len(politico_sent)\n",
    "        politico_2 = politico_sent_count[2]/len(politico_sent)\n",
    "        politico_3 = politico_sent_count[3]/len(politico_sent)\n",
    "        politico_4 = politico_sent_count[4]/len(politico_sent)\n",
    "        politico_5 = politico_sent_count[5]/len(politico_sent)\n",
    "\n",
    "        # Washington Times\n",
    "        washington_times = biden.loc[biden['publisher'] == \"washington_times\"]\n",
    "        washington_times_sent = washington_times['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        washington_times_sent_count = washington_times_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        washington_times_1 = washington_times_sent_count[1]/len(washington_times_sent)\n",
    "        washington_times_2 = washington_times_sent_count[2]/len(washington_times_sent)\n",
    "        washington_times_3 = washington_times_sent_count[3]/len(washington_times_sent)\n",
    "        washington_times_4 = washington_times_sent_count[4]/len(washington_times_sent)\n",
    "        washington_times_5 = washington_times_sent_count[5]/len(washington_times_sent)\n",
    "        \n",
    "        #setup\n",
    "        category_names = ['Extremely negative', 'Negative','Neutral', 'Positive', 'Extremely positive']\n",
    "        publishers = {\n",
    "            'AP': [AP_1, AP_2, AP_3, AP_4, AP_5],\n",
    "            'Breitbart': [Breitbart_1, Breitbart_2, Breitbart_3, Breitbart_4, Breitbart_5],\n",
    "            'Fox': [Fox_1, Fox_2, Fox_3, Fox_4, Fox_5],\n",
    "            'Buzzfeed': [buzzfeed_1, buzzfeed_2, buzzfeed_3, buzzfeed_4, buzzfeed_5],\n",
    "            'NBC': [nbc_1, nbc_2, nbc_3, nbc_4, nbc_5],\n",
    "            'New York Times': [new_york_times_1, new_york_times_2, new_york_times_3, new_york_times_4, new_york_times_5],\n",
    "            'Politico': [politico_1, politico_2, politico_3, politico_4, politico_5],\n",
    "            'Washington Times': [washington_times_1, washington_times_2, washington_times_3, washington_times_4, washington_times_5]\n",
    "        }\n",
    "\n",
    "        def survey(publishers, category_names):\n",
    "            labels = list(publishers.keys())\n",
    "            data = np.array(list(publishers.values()))\n",
    "            data_cum = data.cumsum(axis=1)\n",
    "            category_colors = plt.get_cmap('RdYlGn')(\n",
    "                np.linspace(0.15, 0.85, data.shape[1]))\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            ax.invert_yaxis()\n",
    "            ax.xaxis.set_visible(False)\n",
    "            ax.set_xlim(0, np.sum(data, axis=1).max())\n",
    "\n",
    "            for i, (colname, color) in enumerate(zip(category_names, category_colors)):\n",
    "                widths = data[:, i]\n",
    "                starts = data_cum[:, i] - widths\n",
    "                ax.barh(labels, widths, left=starts, height=0.5,\n",
    "                        label=colname, color=color)\n",
    "                xcenters = starts + widths / 2\n",
    "\n",
    "                r, g, b, _ = color\n",
    "                text_color = 'white' if r * g * b < 0.5 else 'darkgrey'\n",
    "                for y, (x, c) in enumerate(zip(xcenters, widths)):\n",
    "                    ax.text(x, y, str(\"{0:.0%}\".format(c)), ha='center', va='center',\n",
    "                            color=text_color)\n",
    "            ax.legend(ncol=len(category_names), bbox_to_anchor=(0, 1),\n",
    "                      loc='lower left', fontsize='small')\n",
    "\n",
    "            return fig, ax\n",
    "\n",
    "        survey(publishers, category_names)\n",
    "        plt.savefig('sentiment_count_biden.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SentimentAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>publisher</th>\n",
       "      <th>article_text</th>\n",
       "      <th>Trump</th>\n",
       "      <th>Sanders</th>\n",
       "      <th>Biden</th>\n",
       "      <th>Warren</th>\n",
       "      <th>Buttigieg</th>\n",
       "      <th>Bloomberg</th>\n",
       "      <th>Klobuchar</th>\n",
       "      <th>Yang</th>\n",
       "      <th>Steyer</th>\n",
       "      <th>Gabbard</th>\n",
       "      <th>candidates_mentioned</th>\n",
       "      <th>article_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sanders Co-Chair Khanna: ‘Need a Strong Showin...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/07/san...</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>Bernie Sanders’ (I-VT) campaign stated that “...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>bernie sanders ivt campaign stated well michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sanders Co-Chair Khanna: ‘Need a Strong Showin...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/07/san...</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>” Khanna said that while a loss in Michigan wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>khanna said loss michigan wouldnt hurt ration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sanders Co-Chair Khanna: ‘Need a Strong Showin...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/07/san...</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>But as you know, the primary electorate is di...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>know primary electorate different general ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Maher on Matthews Departure: ‘Cancel Culture I...</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/06/mah...</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>Elizabeth Warren (D-MA) over her accusations ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>elizabeth warren dma accusations former new y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>MSNBC’s Hayes: ‘BS Artist’ Trump Coronavirus R...</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/06/msn...</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>MSNBC anchor Chris Hayes criticized President ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>msnbc anchor chris hayes criticized president ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246962</td>\n",
       "      <td>10194</td>\n",
       "      <td>Ukraine’s Massive Cargo Planes — The Biggest I...</td>\n",
       "      <td>2020-04-17 00:00:00</td>\n",
       "      <td>https://www.buzzfeednews.com/article/christoph...</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>5 million in security assistance that Trump pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>million security assistance trump personally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246963</td>\n",
       "      <td>10195</td>\n",
       "      <td>Trump Called Ukrainians “Terrible People.” The...</td>\n",
       "      <td>2020-04-17 00:00:00</td>\n",
       "      <td>https://www.buzzfeednews.com/article/christoph...</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>In May 2019, President Donald Trump desc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>may president donald trump described ukrain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246964</td>\n",
       "      <td>10195</td>\n",
       "      <td>Trump Called Ukrainians “Terrible People.” The...</td>\n",
       "      <td>2020-04-17 00:00:00</td>\n",
       "      <td>https://www.buzzfeednews.com/article/christoph...</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>”The favor Trump wanted — opening investigatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>the favor trump wanted opening investigations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246965</td>\n",
       "      <td>10195</td>\n",
       "      <td>Trump Called Ukrainians “Terrible People.” The...</td>\n",
       "      <td>2020-04-17 00:00:00</td>\n",
       "      <td>https://www.buzzfeednews.com/article/christoph...</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>But months later, as the coronavirus pandemic ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>but months later coronavirus pandemic ravages ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246966</td>\n",
       "      <td>10195</td>\n",
       "      <td>Trump Called Ukrainians “Terrible People.” The...</td>\n",
       "      <td>2020-04-17 00:00:00</td>\n",
       "      <td>https://www.buzzfeednews.com/article/christoph...</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>5 million in security assistance that Trump pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>million security assistance trump personally ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246967 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id                                      article_title  \\\n",
       "0                0  Sanders Co-Chair Khanna: ‘Need a Strong Showin...   \n",
       "1                0  Sanders Co-Chair Khanna: ‘Need a Strong Showin...   \n",
       "2                0  Sanders Co-Chair Khanna: ‘Need a Strong Showin...   \n",
       "3                1  Maher on Matthews Departure: ‘Cancel Culture I...   \n",
       "4                2  MSNBC’s Hayes: ‘BS Artist’ Trump Coronavirus R...   \n",
       "...            ...                                                ...   \n",
       "246962       10194  Ukraine’s Massive Cargo Planes — The Biggest I...   \n",
       "246963       10195  Trump Called Ukrainians “Terrible People.” The...   \n",
       "246964       10195  Trump Called Ukrainians “Terrible People.” The...   \n",
       "246965       10195  Trump Called Ukrainians “Terrible People.” The...   \n",
       "246966       10195  Trump Called Ukrainians “Terrible People.” The...   \n",
       "\n",
       "                       date  \\\n",
       "0                2020-03-07   \n",
       "1                2020-03-07   \n",
       "2                2020-03-07   \n",
       "3                2020-03-06   \n",
       "4                2020-03-06   \n",
       "...                     ...   \n",
       "246962  2020-04-17 00:00:00   \n",
       "246963  2020-04-17 00:00:00   \n",
       "246964  2020-04-17 00:00:00   \n",
       "246965  2020-04-17 00:00:00   \n",
       "246966  2020-04-17 00:00:00   \n",
       "\n",
       "                                                     link  publisher  \\\n",
       "0       https://www.breitbart.com/clips/2020/03/07/san...  Breitbart   \n",
       "1       https://www.breitbart.com/clips/2020/03/07/san...  Breitbart   \n",
       "2       https://www.breitbart.com/clips/2020/03/07/san...  Breitbart   \n",
       "3       https://www.breitbart.com/clips/2020/03/06/mah...  Breitbart   \n",
       "4       https://www.breitbart.com/clips/2020/03/06/msn...  Breitbart   \n",
       "...                                                   ...        ...   \n",
       "246962  https://www.buzzfeednews.com/article/christoph...   buzzfeed   \n",
       "246963  https://www.buzzfeednews.com/article/christoph...   buzzfeed   \n",
       "246964  https://www.buzzfeednews.com/article/christoph...   buzzfeed   \n",
       "246965  https://www.buzzfeednews.com/article/christoph...   buzzfeed   \n",
       "246966  https://www.buzzfeednews.com/article/christoph...   buzzfeed   \n",
       "\n",
       "                                             article_text  Trump  Sanders  \\\n",
       "0        Bernie Sanders’ (I-VT) campaign stated that “...      0        1   \n",
       "1       ” Khanna said that while a loss in Michigan wo...      0        1   \n",
       "2        But as you know, the primary electorate is di...      1        1   \n",
       "3        Elizabeth Warren (D-MA) over her accusations ...      0        0   \n",
       "4       MSNBC anchor Chris Hayes criticized President ...      1        0   \n",
       "...                                                   ...    ...      ...   \n",
       "246962  5 million in security assistance that Trump pe...      1        0   \n",
       "246963        In May 2019, President Donald Trump desc...      1        0   \n",
       "246964  ”The favor Trump wanted — opening investigatio...      1        0   \n",
       "246965  But months later, as the coronavirus pandemic ...      1        0   \n",
       "246966  5 million in security assistance that Trump pe...      1        0   \n",
       "\n",
       "        Biden  Warren  Buttigieg  Bloomberg  Klobuchar  Yang  Steyer  Gabbard  \\\n",
       "0           0       0          0          0          0     0       0        0   \n",
       "1           0       0          0          0          0     0       0        0   \n",
       "2           0       0          0          0          0     0       0        0   \n",
       "3           0       1          0          1          0     0       0        0   \n",
       "4           0       0          0          0          0     0       0        0   \n",
       "...       ...     ...        ...        ...        ...   ...     ...      ...   \n",
       "246962      0       0          0          0          0     0       0        0   \n",
       "246963      0       0          0          0          0     0       0        0   \n",
       "246964      1       0          0          0          0     0       0        0   \n",
       "246965      0       0          0          0          0     0       0        0   \n",
       "246966      0       0          0          0          0     0       0        0   \n",
       "\n",
       "        candidates_mentioned  \\\n",
       "0                          1   \n",
       "1                          1   \n",
       "2                          2   \n",
       "3                          2   \n",
       "4                          1   \n",
       "...                      ...   \n",
       "246962                     1   \n",
       "246963                     1   \n",
       "246964                     2   \n",
       "246965                     1   \n",
       "246966                     1   \n",
       "\n",
       "                                       article_text_clean  \n",
       "0        bernie sanders ivt campaign stated well michigan  \n",
       "1        khanna said loss michigan wouldnt hurt ration...  \n",
       "2        know primary electorate different general ele...  \n",
       "3        elizabeth warren dma accusations former new y...  \n",
       "4       msnbc anchor chris hayes criticized president ...  \n",
       "...                                                   ...  \n",
       "246962   million security assistance trump personally ...  \n",
       "246963     may president donald trump described ukrain...  \n",
       "246964  the favor trump wanted opening investigations ...  \n",
       "246965  but months later coronavirus pandemic ravages ...  \n",
       "246966   million security assistance trump personally ...  \n",
       "\n",
       "[246967 rows x 18 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.sentence_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>publisher</th>\n",
       "      <th>article_text</th>\n",
       "      <th>Trump</th>\n",
       "      <th>Sanders</th>\n",
       "      <th>Biden</th>\n",
       "      <th>Warren</th>\n",
       "      <th>Buttigieg</th>\n",
       "      <th>Bloomberg</th>\n",
       "      <th>Klobuchar</th>\n",
       "      <th>Yang</th>\n",
       "      <th>Steyer</th>\n",
       "      <th>Gabbard</th>\n",
       "      <th>candidates_mentioned</th>\n",
       "      <th>article_text_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sanders Co-Chair Khanna: ‘Need a Strong Showin...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/07/san...</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>Bernie Sanders’ (I-VT) campaign stated that “...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>bernie sanders ivt campaign stated well michigan</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sanders Co-Chair Khanna: ‘Need a Strong Showin...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/07/san...</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>” Khanna said that while a loss in Michigan wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>khanna said loss michigan wouldnt hurt ration...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sanders Co-Chair Khanna: ‘Need a Strong Showin...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/07/san...</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>But as you know, the primary electorate is di...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>know primary electorate different general ele...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Maher on Matthews Departure: ‘Cancel Culture I...</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/06/mah...</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>Elizabeth Warren (D-MA) over her accusations ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>elizabeth warren dma accusations former new y...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>MSNBC’s Hayes: ‘BS Artist’ Trump Coronavirus R...</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/06/msn...</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>MSNBC anchor Chris Hayes criticized President ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>msnbc anchor chris hayes criticized president ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246962</td>\n",
       "      <td>10194</td>\n",
       "      <td>Ukraine’s Massive Cargo Planes — The Biggest I...</td>\n",
       "      <td>2020-04-17 00:00:00</td>\n",
       "      <td>https://www.buzzfeednews.com/article/christoph...</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>5 million in security assistance that Trump pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>million security assistance trump personally ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246963</td>\n",
       "      <td>10195</td>\n",
       "      <td>Trump Called Ukrainians “Terrible People.” The...</td>\n",
       "      <td>2020-04-17 00:00:00</td>\n",
       "      <td>https://www.buzzfeednews.com/article/christoph...</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>In May 2019, President Donald Trump desc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>may president donald trump described ukrain...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246964</td>\n",
       "      <td>10195</td>\n",
       "      <td>Trump Called Ukrainians “Terrible People.” The...</td>\n",
       "      <td>2020-04-17 00:00:00</td>\n",
       "      <td>https://www.buzzfeednews.com/article/christoph...</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>”The favor Trump wanted — opening investigatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>the favor trump wanted opening investigations ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246965</td>\n",
       "      <td>10195</td>\n",
       "      <td>Trump Called Ukrainians “Terrible People.” The...</td>\n",
       "      <td>2020-04-17 00:00:00</td>\n",
       "      <td>https://www.buzzfeednews.com/article/christoph...</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>But months later, as the coronavirus pandemic ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>but months later coronavirus pandemic ravages ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246966</td>\n",
       "      <td>10195</td>\n",
       "      <td>Trump Called Ukrainians “Terrible People.” The...</td>\n",
       "      <td>2020-04-17 00:00:00</td>\n",
       "      <td>https://www.buzzfeednews.com/article/christoph...</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>5 million in security assistance that Trump pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>million security assistance trump personally ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246967 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id                                      article_title  \\\n",
       "0                0  Sanders Co-Chair Khanna: ‘Need a Strong Showin...   \n",
       "1                0  Sanders Co-Chair Khanna: ‘Need a Strong Showin...   \n",
       "2                0  Sanders Co-Chair Khanna: ‘Need a Strong Showin...   \n",
       "3                1  Maher on Matthews Departure: ‘Cancel Culture I...   \n",
       "4                2  MSNBC’s Hayes: ‘BS Artist’ Trump Coronavirus R...   \n",
       "...            ...                                                ...   \n",
       "246962       10194  Ukraine’s Massive Cargo Planes — The Biggest I...   \n",
       "246963       10195  Trump Called Ukrainians “Terrible People.” The...   \n",
       "246964       10195  Trump Called Ukrainians “Terrible People.” The...   \n",
       "246965       10195  Trump Called Ukrainians “Terrible People.” The...   \n",
       "246966       10195  Trump Called Ukrainians “Terrible People.” The...   \n",
       "\n",
       "                       date  \\\n",
       "0                2020-03-07   \n",
       "1                2020-03-07   \n",
       "2                2020-03-07   \n",
       "3                2020-03-06   \n",
       "4                2020-03-06   \n",
       "...                     ...   \n",
       "246962  2020-04-17 00:00:00   \n",
       "246963  2020-04-17 00:00:00   \n",
       "246964  2020-04-17 00:00:00   \n",
       "246965  2020-04-17 00:00:00   \n",
       "246966  2020-04-17 00:00:00   \n",
       "\n",
       "                                                     link  publisher  \\\n",
       "0       https://www.breitbart.com/clips/2020/03/07/san...  Breitbart   \n",
       "1       https://www.breitbart.com/clips/2020/03/07/san...  Breitbart   \n",
       "2       https://www.breitbart.com/clips/2020/03/07/san...  Breitbart   \n",
       "3       https://www.breitbart.com/clips/2020/03/06/mah...  Breitbart   \n",
       "4       https://www.breitbart.com/clips/2020/03/06/msn...  Breitbart   \n",
       "...                                                   ...        ...   \n",
       "246962  https://www.buzzfeednews.com/article/christoph...   buzzfeed   \n",
       "246963  https://www.buzzfeednews.com/article/christoph...   buzzfeed   \n",
       "246964  https://www.buzzfeednews.com/article/christoph...   buzzfeed   \n",
       "246965  https://www.buzzfeednews.com/article/christoph...   buzzfeed   \n",
       "246966  https://www.buzzfeednews.com/article/christoph...   buzzfeed   \n",
       "\n",
       "                                             article_text  Trump  Sanders  \\\n",
       "0        Bernie Sanders’ (I-VT) campaign stated that “...      0        1   \n",
       "1       ” Khanna said that while a loss in Michigan wo...      0        1   \n",
       "2        But as you know, the primary electorate is di...      1        1   \n",
       "3        Elizabeth Warren (D-MA) over her accusations ...      0        0   \n",
       "4       MSNBC anchor Chris Hayes criticized President ...      1        0   \n",
       "...                                                   ...    ...      ...   \n",
       "246962  5 million in security assistance that Trump pe...      1        0   \n",
       "246963        In May 2019, President Donald Trump desc...      1        0   \n",
       "246964  ”The favor Trump wanted — opening investigatio...      1        0   \n",
       "246965  But months later, as the coronavirus pandemic ...      1        0   \n",
       "246966  5 million in security assistance that Trump pe...      1        0   \n",
       "\n",
       "        Biden  Warren  Buttigieg  Bloomberg  Klobuchar  Yang  Steyer  Gabbard  \\\n",
       "0           0       0          0          0          0     0       0        0   \n",
       "1           0       0          0          0          0     0       0        0   \n",
       "2           0       0          0          0          0     0       0        0   \n",
       "3           0       1          0          1          0     0       0        0   \n",
       "4           0       0          0          0          0     0       0        0   \n",
       "...       ...     ...        ...        ...        ...   ...     ...      ...   \n",
       "246962      0       0          0          0          0     0       0        0   \n",
       "246963      0       0          0          0          0     0       0        0   \n",
       "246964      1       0          0          0          0     0       0        0   \n",
       "246965      0       0          0          0          0     0       0        0   \n",
       "246966      0       0          0          0          0     0       0        0   \n",
       "\n",
       "        candidates_mentioned  \\\n",
       "0                          1   \n",
       "1                          1   \n",
       "2                          2   \n",
       "3                          2   \n",
       "4                          1   \n",
       "...                      ...   \n",
       "246962                     1   \n",
       "246963                     1   \n",
       "246964                     2   \n",
       "246965                     1   \n",
       "246966                     1   \n",
       "\n",
       "                                       article_text_clean  sentiment  \n",
       "0        bernie sanders ivt campaign stated well michigan          3  \n",
       "1        khanna said loss michigan wouldnt hurt ration...          3  \n",
       "2        know primary electorate different general ele...          4  \n",
       "3        elizabeth warren dma accusations former new y...          3  \n",
       "4       msnbc anchor chris hayes criticized president ...          3  \n",
       "...                                                   ...        ...  \n",
       "246962   million security assistance trump personally ...          3  \n",
       "246963     may president donald trump described ukrain...          2  \n",
       "246964  the favor trump wanted opening investigations ...          3  \n",
       "246965  but months later coronavirus pandemic ravages ...          3  \n",
       "246966   million security assistance trump personally ...          3  \n",
       "\n",
       "[246967 rows x 19 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.sentiment_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_mean</th>\n",
       "      <th>sanders_sent_mean</th>\n",
       "      <th>biden_sent_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.112837</td>\n",
       "      <td>3.191718</td>\n",
       "      <td>3.149492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_mean  sanders_sent_mean  biden_sent_mean\n",
       "0   3.112837           3.191718         3.149492"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.candidate_sentiment_means()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2b8b527e3d43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment_time_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# not working in OOP\n",
    "sa.sentiment_time_plot()\n",
    "sa.sanders_sentiment_plot()\n",
    "sa.biden_sentiment_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
