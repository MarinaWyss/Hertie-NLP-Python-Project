{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import transformers\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "x_train = torch.load(\"x_train\")\n",
    "x_val = torch.load(\"x_val\")\n",
    "x_test = torch.load(\"x_test\")\n",
    "y_train = torch.load(\"y_train\")\n",
    "y_val = torch.load(\"y_val\")\n",
    "y_test = torch.load(\"y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KimCNN(nn.Module):\n",
    "    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout, static):\n",
    "        super(KimCNN, self).__init__()\n",
    "        V = embed_num\n",
    "        D = embed_dim\n",
    "        C = class_num\n",
    "        Co = kernel_num\n",
    "        Ks = kernel_sizes\n",
    "        \n",
    "        self.static = static\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, D)) for K in Ks])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.static:\n",
    "            x = Variable(x)\n",
    "        x = x.unsqueeze(1)  \n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  \n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  \n",
    "        x = torch.cat(x, 1) \n",
    "        x = self.dropout(x)  \n",
    "        logit = self.fc1(x)  \n",
    "        output = self.sigmoid(logit) \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "embed_num = x_train2.shape[1]\n",
    "embed_dim = x_train2.shape[2] \n",
    "class_num = y_train2.shape[1] \n",
    "kernel_num = 3 \n",
    "kernel_sizes = [2, 3, 4] \n",
    "dropout = 0.1 \n",
    "static = True\n",
    "\n",
    "model = KimCNN(\n",
    "    embed_num=embed_num,\n",
    "    embed_dim=embed_dim,\n",
    "    class_num=class_num,\n",
    "    kernel_num=kernel_num,\n",
    "    kernel_sizes=kernel_sizes,\n",
    "    dropout=dropout,\n",
    "    static=static,\n",
    ")\n",
    "\n",
    "n_epochs = 10 \n",
    "lr = 0.0001 \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) \n",
    "loss_fn = nn.BCELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0\n",
    "    model.train(True)\n",
    "    y_pred = model(x_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()\n",
    "    train_losses.append(train_loss)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(\"Epoch %d. Train loss: %.2f. Elapsed time: %.2fs.\"\n",
    "    % (epoch + 1, train_losses[-1], elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    val_loss = 0\n",
    "    model.eval() \n",
    "    y_pred = model(x_val)\n",
    "    loss = loss_fn(y_pred, y_val)\n",
    "    val_loss += loss.item()\n",
    "    val_losses.append(val_loss)\n",
    "    print(\"Epoch %d. Validation loss: %.2f. Elapsed time: %.2fs.\"\n",
    "    % (epoch + 1, val_losses[-1], elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.plot(train_losses, label=\"Training loss\")\n",
    "plt.plot(val_losses, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "model.eval() \n",
    "\n",
    "with torch.no_grad():\n",
    "    y_preds = []\n",
    "    y_pred = model(x_test)\n",
    "    y_preds.extend(y_pred.cpu().numpy().tolist())\n",
    "    y_preds_np = np.array(y_preds)\n",
    "\n",
    "y_preds_np = (y_preds_np > 0.5)\n",
    "y_test_np = y_test.numpy()\n",
    "\n",
    "print(classification_report(y_test_np, y_preds_np))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
