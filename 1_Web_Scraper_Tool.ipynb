{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper Tool for 5 US Media Outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Breitbart - Very Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "breitbart_request = requests.get('https://www.breitbart.com/politics/')\n",
    "breitbart_homepage = breitbart_request.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup \n",
    "breitbart_soup = BeautifulSoup(breitbart_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# locate article URLs\n",
    "breitbart_tags = breitbart_soup.find_all('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_articles = 30\n",
    "\n",
    "# get article titles, content, and links\n",
    "breitbart_links = []\n",
    "breitbart_titles = []\n",
    "breitbart_dates = []\n",
    "breitbart_contents = []\n",
    "\n",
    "for n in np.arange(0, number_of_articles):\n",
    "\n",
    "    # get article link\n",
    "    link = breitbart_tags[n].find('a')['href']\n",
    "    link = \"https://www.breitbart.com\" + link\n",
    "    breitbart_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = breitbart_tags[n].find('a').get_text()\n",
    "    breitbart_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.time.attrs['datetime']\n",
    "    breitbart_dates.append(date)\n",
    "    \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', class_='entry-content')\n",
    "    x = body[0].find_all('p')\n",
    "\n",
    "    # combine paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        list_paragraphs.append(paragraph)\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "        \n",
    "    breitbart_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "breitbart_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'Breitbart',\n",
    "    'date': breitbart_dates,\n",
    "    'link': breitbart_links,\n",
    "    'article_title': breitbart_titles,\n",
    "    'article_text': breitbart_contents \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On Friday’s broadcast of MSNBC’s “11th Hour,” ...</td>\n",
       "      <td>Sanders Co-Chair Khanna: ‘Need a Strong Showin...</td>\n",
       "      <td>2020-03-07T00:12:05Z</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/07/san...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On Friday’s broadcast of HBO’s “Real Time,” ho...</td>\n",
       "      <td>Maher on Matthews Departure: ‘Cancel Culture I...</td>\n",
       "      <td>2020-03-06T21:58:50Z</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/06/mah...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSNBC anchor Chris Hayes criticized President ...</td>\n",
       "      <td>MSNBC’s Hayes: ‘BS Artist’ Trump Coronavirus R...</td>\n",
       "      <td>2020-03-06T20:40:26Z</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/06/msn...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>President Donald Trump has fortified his White...</td>\n",
       "      <td>‘The Perfect Choice’: Trump Brings Warrior Mar...</td>\n",
       "      <td>2020-03-06T19:59:49Z</td>\n",
       "      <td>https://www.breitbart.com/politics/2020/03/06/...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ammunition sales are surging amid fears of pan...</td>\n",
       "      <td>Ammo Sales Surge amid Fears of Pandemic-Induce...</td>\n",
       "      <td>2020-03-06T18:54:06Z</td>\n",
       "      <td>https://www.breitbart.com/2nd-amendment/2020/0...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_text  \\\n",
       "0  On Friday’s broadcast of MSNBC’s “11th Hour,” ...   \n",
       "1  On Friday’s broadcast of HBO’s “Real Time,” ho...   \n",
       "2  MSNBC anchor Chris Hayes criticized President ...   \n",
       "3  President Donald Trump has fortified his White...   \n",
       "4  Ammunition sales are surging amid fears of pan...   \n",
       "\n",
       "                                       article_title                  date  \\\n",
       "0  Sanders Co-Chair Khanna: ‘Need a Strong Showin...  2020-03-07T00:12:05Z   \n",
       "1  Maher on Matthews Departure: ‘Cancel Culture I...  2020-03-06T21:58:50Z   \n",
       "2  MSNBC’s Hayes: ‘BS Artist’ Trump Coronavirus R...  2020-03-06T20:40:26Z   \n",
       "3  ‘The Perfect Choice’: Trump Brings Warrior Mar...  2020-03-06T19:59:49Z   \n",
       "4  Ammo Sales Surge amid Fears of Pandemic-Induce...  2020-03-06T18:54:06Z   \n",
       "\n",
       "                                                link  publisher  \n",
       "0  https://www.breitbart.com/clips/2020/03/07/san...  Breitbart  \n",
       "1  https://www.breitbart.com/clips/2020/03/06/mah...  Breitbart  \n",
       "2  https://www.breitbart.com/clips/2020/03/06/msn...  Breitbart  \n",
       "3  https://www.breitbart.com/politics/2020/03/06/...  Breitbart  \n",
       "4  https://www.breitbart.com/2nd-amendment/2020/0...  Breitbart  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breitbart_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in old data\n",
    "old_breitbart_data = pd.read_csv('data/breitbart_data.csv')\n",
    "\n",
    "# append new data\n",
    "breitbart_data = old_breitbart_data.append(breitbart_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "breitbart_data.to_csv(\"data/breitbart_data.csv\", index = False)"

    "### 2. Fox - Conservative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get links from the Fox Politics homepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "fox_request = requests.get('https://www.foxnews.com/politics')\n",
    "fox_homepage = fox_request.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup\n",
    "fox_soup = BeautifulSoup(fox_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate article URLs - CHECK FOR BETTER WAY TO ISOLATE ARTICLE LINKS\n",
    "fox_tags = fox_soup.find_all('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://foxnews.com/politics/will-female-youth-and-minority-voters-lose-interest-in-2020-as-race-comes-down-to-3-white-septuagenarians', 'https://foxnews.com/politics/trump-to-visit-tennessee-tornadoes', 'https://foxnews.com/politics/trump-cancels-trip-to-cdc-amid-coronavirus-outbreak', 'https://foxnews.com/politics/ocasio-cortez-illegal-immigrants-2020-census', 'https://foxnews.com/politics/house-prepares-telework-scenarios-amid-coronavirus-threat', 'https://foxnews.com/politics/tulsi-gabbard-calls-on-biden-sanders-to-demand-dnc-allow-her-on-arizona-debate-stage', 'https://foxnews.com/politics/fox-news-voter-analysis-biden-sanders-emerge-from-dem-pack-on-super-tuesday', 'https://foxnews.com/politics/fox-news-poll-trump-economy-failed-to-unify', 'https://foxnews.com/politics/fox-news-poll-capitalism-socialism-bernie-sanders', 'https://foxnews.com/politics/fox-news-poll-sanders-knocks-biden-out-of-first-majority-thinks-trump-wins', 'https://foxnews.com/politics/trump-mark-meadows-white-house-chief-of-staff-mick-mulvaney', 'https://foxnews.com/politics/trump-to-award-golfers-annika-sorenstam-gary-j-player-the-presidential-medal-of-freedom', 'https://foxnews.com/politics/doj-responds-after-judge-slams-ag-barr-over-mueller-report', 'https://foxnews.com/media/gender-questions-swirl-as-warren-leaves-race-to-two-old-men', 'https://foxnews.com/media/bloomberg-investment-bombs-as-press-belatedly-boosts-biden']\n"
     ]
    }
   ],
   "source": [
    "number_of_articles = 30\n",
    "\n",
    "# get article titles, content, and links\n",
    "fox_links = []\n",
    "fox_title = []\n",
    "fox_date_published = []\n",
    "fox_description = []\n",
    "fox_text = []\n",
    "fox_url = []\n",
    "\n",
    "for n in np.arange(0, number_of_articles):\n",
    "\n",
    "    # get article link\n",
    "    link = fox_tags[n].find('a')\n",
    "    link = link.get('href')\n",
    "    link = \"https://foxnews.com\" + link\n",
    "    fox_links.append(link)\n",
    "    fox_links = [x for x in fox_links if \"/v/\" not in x] \n",
    "    \n",
    "    # get article title\n",
    "    title = breitbart_tags[n].find('a').get_text()\n",
    "    breitbart_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.time.attrs['datetime']\n",
    "    breitbart_dates.append(date)\n",
    "    \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', class_='entry-content')\n",
    "    x = body[0].find_all('p')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get article text and other relevent data from new articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "headline = []\n",
    "date_published = []\n",
    "date_modified = []\n",
    "description = []\n",
    "author = []\n",
    "url = []\n",
    "\n",
    "for link in hp_fox_links:\n",
    "    # load the HTML content using requests and save into a variable\n",
    "    fox_article_request = requests.get(link)\n",
    "    fox_article = fox_article_request.content\n",
    "\n",
    "    # create a soups to allow BeautifulSoup to work\n",
    "    fox_article_soup = BeautifulSoup(fox_article, 'html.parser')\n",
    "\n",
    "    # get article text\n",
    "    fox_article_text = fox_article_soup.find(\"body\").get_text()\n",
    "    text.append(text)\n",
    "    \n",
    "    # retrieve article specific metadata\n",
    "    fox_metadata = fox_article_soup.find_all(\"script\")[2].get_text()\n",
    "    fox_metadata = fox_metadata.split(\",\")\n",
    "\n",
    "    for item in fox_metadata:\n",
    "        if 'headline' in item:\n",
    "            headline.append(item)\n",
    "        elif 'datePublished' in item:\n",
    "            date_published.append(item)\n",
    "        elif 'dateModified' in item:\n",
    "            date_modified.append(item)\n",
    "        elif 'description' in item:\n",
    "            description.append(item)\n",
    "        elif 'name' in item and 'Fox News' not in item:\n",
    "            author.append(item)\n",
    "        elif 'mainEntityOfPage' in item:\n",
    "            url.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 22\n",
      "headline 22\n",
      "date_published 22\n",
      "date_modified 22\n",
      "description 22\n",
      "author 21\n",
      "url 22\n"
     ]
    }
   ],
   "source": [
    "print('text', len(text))\n",
    "print('headline', len(headline))\n",
    "print('date_published', len(date_published))\n",
    "print('date_modified', len(date_modified))\n",
    "print('description', len(description))\n",
    "print('author', len(author))\n",
    "print('url', len(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#article_data2 = pd.DataFrame({'text':text,'title':headline, 'date_published':date_published, 'date_modified':date_modified, 'description':description, 'author':author, 'url':url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collection of all responses\n",
    "all_articles2 = pd.read_csv(\"Fox_Data.csv\", index_col=[0])\n",
    "\n",
    "# merge new increment of data to the csv\n",
    "all_articles2 = article_data2.append(article_data2, ignore_index=True)\n",
    "\n",
    "#export with new increment to save\n",
    "all_articles.to_csv('Fox_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<meta content=\"Dana Blanton\" data-hid=\"dc.creator\" data-n-head=\"true\" name=\"dc.creator\" scheme=\"dcterms.creator\"/>\n"
     ]
    }
   ],
   "source": [
    "# another spot the author is located just in case\n",
    "# test = article_soup3.find_all(\"meta\")[17]\n",
    "#print(yay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Wall Street Journal - neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "wsj_request = requests.get('https://www.wsj.com/news/politics')\n",
    "wsj_homepage = wsj_request.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup \n",
    "wsj_soup = BeautifulSoup(wsj_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate article URLs\n",
    "wsj_tags = wsj_soup.find_all('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "wsj_links = []\n",
    "\n",
    "for link in wsj_tags:\n",
    "    wsj_links.append(link.get('href'))\n",
    "\n",
    "print(wsj_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_articles = 30\n",
    "\n",
    "# get article titles, content, and links\n",
    "wsj_links = []\n",
    "wsj_titles = []\n",
    "wsj_dates = []\n",
    "wsj_contents = []\n",
    "\n",
    "for n in np.arange(0, number_of_articles):\n",
    "\n",
    "    # get article link\n",
    "    link = wsj_tags[n].find('a')['href']\n",
    "    link = \"https://www.wsj.com\" + link\n",
    "    wsj_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = wsj_tags[n].find('a').get_text()\n",
    "    wsj_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.time.attrs['datetime']\n",
    "    wsj_dates.append(date)\n",
    "    \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', class_='entry-content')\n",
    "    x = body[0].find_all('p')\n",
    "    \n",
    "    # combine paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        list_paragraphs.append(paragraph)\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "        \n",
    "    wsj_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breitbart_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'Breitbart',\n",
    "    'date': breitbart_dates,\n",
    "    'link': breitbart_links,\n",
    "    'article_title': breitbart_titles,\n",
    "    'article_text': breitbart_contents \n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
