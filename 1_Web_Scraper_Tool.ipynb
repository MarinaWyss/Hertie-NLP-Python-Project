{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper Tool for 5 US Media Outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Breitbart - Very Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "breitbart_request = requests.get('https://www.breitbart.com/politics/')\n",
    "breitbart_homepage = breitbart_request.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup \n",
    "breitbart_soup = BeautifulSoup(breitbart_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# locate article URLs\n",
    "breitbart_tags = breitbart_soup.find_all('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_articles = min(len(breitbart_tags), 30)\n",
    "\n",
    "# get article titles, content, and links\n",
    "breitbart_links = []\n",
    "breitbart_titles = []\n",
    "breitbart_dates = []\n",
    "breitbart_contents = []\n",
    "\n",
    "for n in np.arange(0, number_of_articles):\n",
    "\n",
    "    # get article link\n",
    "    link = breitbart_tags[n].find('a')['href']\n",
    "    link = \"https://www.breitbart.com\" + link\n",
    "    breitbart_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = breitbart_tags[n].find('a').get_text()\n",
    "    breitbart_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.time.attrs['datetime']\n",
    "    date = date[:-10]\n",
    "    breitbart_dates.append(date)\n",
    "    \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', class_='entry-content')\n",
    "    x = body[0].find_all('p')\n",
    "    \n",
    "    # combine paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        list_paragraphs.append(paragraph)\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "        \n",
    "    breitbart_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembling data\n",
    "breitbart_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'Breitbart',\n",
    "    'date': breitbart_dates,\n",
    "    'link': breitbart_links,\n",
    "    'article_title': breitbart_titles,\n",
    "    'article_text': breitbart_contents \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A group of Conservative party grandees will se...</td>\n",
       "      <td>Tories Rebel over Huawei: As ‘Ridiculous’ as G...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/europe/2020/03/07/to...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greece has accused the Turkish government of s...</td>\n",
       "      <td>Greece Denounces ‘Fake News’ as Turkey Claims ...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/europe/2020/03/07/gr...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dramatic pictures and video are emerging of fi...</td>\n",
       "      <td>PICTURES: Greek Border in Flames as Migrants K...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/europe/2020/03/07/pi...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finland’s millennial feminist-led government f...</td>\n",
       "      <td>Finland’s Millennial Feminist Govt to Help Gre...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/europe/2020/03/07/fi...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A total of 76 per cent of the Greek public sup...</td>\n",
       "      <td>Nearly 8 in 10 Greeks Support Government’s Bor...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/europe/2020/03/07/ne...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_text  \\\n",
       "0  A group of Conservative party grandees will se...   \n",
       "1  Greece has accused the Turkish government of s...   \n",
       "2  Dramatic pictures and video are emerging of fi...   \n",
       "3  Finland’s millennial feminist-led government f...   \n",
       "4  A total of 76 per cent of the Greek public sup...   \n",
       "\n",
       "                                       article_title        date  \\\n",
       "0  Tories Rebel over Huawei: As ‘Ridiculous’ as G...  2020-03-07   \n",
       "1  Greece Denounces ‘Fake News’ as Turkey Claims ...  2020-03-07   \n",
       "2  PICTURES: Greek Border in Flames as Migrants K...  2020-03-07   \n",
       "3  Finland’s Millennial Feminist Govt to Help Gre...  2020-03-07   \n",
       "4  Nearly 8 in 10 Greeks Support Government’s Bor...  2020-03-07   \n",
       "\n",
       "                                                link  publisher  \n",
       "0  https://www.breitbart.com/europe/2020/03/07/to...  Breitbart  \n",
       "1  https://www.breitbart.com/europe/2020/03/07/gr...  Breitbart  \n",
       "2  https://www.breitbart.com/europe/2020/03/07/pi...  Breitbart  \n",
       "3  https://www.breitbart.com/europe/2020/03/07/fi...  Breitbart  \n",
       "4  https://www.breitbart.com/europe/2020/03/07/ne...  Breitbart  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it looks nice\n",
    "breitbart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in old data\n",
    "old_breitbart_data = pd.read_csv('data/breitbart_data.csv')\n",
    "\n",
    "# append new data\n",
    "breitbart_data = old_breitbart_data.append(breitbart_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "breitbart_data.to_csv(\"data/breitbart_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fox - Conservative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get links from the Fox Politics homepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.foxnews.com/category/politics/2020-presidential-election <- 127 links // 15  without junk\n",
    "# https://www.foxnews.com/politics <- 150 links (but junk?) // 31 without junk\n",
    "# i also tried running this for each candidate's section but there is overlap in articles\n",
    "\n",
    "# load the HTML content using requests and save into a variable\n",
    "r2 = requests.get('https://www.foxnews.com/politics')\n",
    "homepage2 = r2.content\n",
    "\n",
    "# create a soup to allow BeautifulSoup to work\n",
    "soup2 = BeautifulSoup(homepage2, 'html.parser')\n",
    "\n",
    "# locate and retrieve all links - WAS NOT ABLE TO ISOLATE JUST ARTICLE LINKS BECUASE NO UNIQUE TAG ELEMENT!!\n",
    "# you can see how complex the homepage is: print(soup2.prettify())\n",
    "homepage_tags2 = soup2.find_all('a')\n",
    "homepage_links2 = []\n",
    "\n",
    "for link in homepage_tags2:\n",
    "    homepage_links2.append(link.get('href'))\n",
    "\n",
    "# remove duplicates by turning list into a set\n",
    "homepage_links2 = set(homepage_links2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove junk links from list <- MAYBE THIS COULD BE DONE IN A BETTER WAY??\n",
    "# creating a list of exact junk links that will never be needed when pulling from the homepage\n",
    "junk_links2 = ['/', '/us', '/world', '/opinion', '/politics', '/entertainment', '//www.foxbusiness.com', \n",
    "                  '/lifestyle', '/shows', '//www.foxnews.com/shows/fox-nation', '//radio.foxnews.com/podcast',\n",
    "                  '#', '//foxnews.com/weather/your-weather/index.html', '#', '#', \n",
    "                  '//video.foxnews.com/v/5614615980001/?#sp=watch-live', '#', '/us', '/world', '/opinion', '/politics', \n",
    "                  '/official-polls', '/category/politics/elections', \n",
    "                  '/entertainment', '//video.foxnews.com/playlist/entertainment-latest-entertainment/', \n",
    "                  '//www.foxbusiness.com/', '//www.foxbusiness.com/markets', '//www.foxbusiness.com/politics', \n",
    "                  '//www.foxbusiness.com/category/technology', '//www.foxbusiness.com/features', \n",
    "                  '//www.foxbusiness.com/category/business-leaders', '/lifestyle', '/food-drink', '/auto', \n",
    "                  '/travel', '/family', '/science', '/tech', '/health', '/shows', '/shows', \n",
    "                  '/person/personalities', '//video.foxnews.com/v/5614615980001/?#sp=watch-live', \n",
    "                  '//video.foxnews.com/playlist/episodic-most-recent-episodes/', \n",
    "                  '//video.foxnews.com/#sp=show-clips', '//video.foxnews.com/#sp=news-clips', \n",
    "                  '//www.foxnews.com/contact', '//foxcareers.com/Search/SearchResults?brand=Fox%20News%20Careers', \n",
    "                  '/foxaroundtheworld/', 'mailto:adsales@foxnews.com?subject=Advertising%20Inquiry', \n",
    "                  '//press.foxnews.com/media-contacts/', '//press.foxnews.com/', '/compliance', \n",
    "                  'https://supplierdiversity.foxnews.com/', '//www.foxnews.com/shows/fox-nation', '//shop.foxnews.com', \n",
    "                  '/go', '//radio.foxnews.com/', '/alerts/subscribe', '/newsletter-signup/alerts', '//radio.foxnews.com/podcast', \n",
    "                  '/apps-products', '//www.foxnews.com', '/terms-of-use', '/privacy-policy', '/donotsell', '/closed-captioning', \n",
    "                  '//help.foxnews.com', '/contact', '//www.facebook.com/FoxNews', '//twitter.com/foxnews', '//www.google.com/+FoxNews', \n",
    "                  '//www.instagram.com/foxnews', '/about/rss/', '/alerts/subscribe', 'https://flipboard.com/@FoxNews', \n",
    "                  '//www.foxnews.com/rss/index.html', '//www.foxnews.com/alerts/subscribe.html', \n",
    "                   '/accessibility-statement', 'https://video.foxnews.com/v/', 'https://foxnews.com/elections']\n",
    "\n",
    "# removing all links that lead to section pages AND other specified junk URLs\n",
    "homepage_links2 = [x for x in homepage_links2 if \"/category\" not in x] \n",
    "homepage_links2 = [x for x in homepage_links2 if \"/v/\" not in x] \n",
    "homepage_links2 = [x for x in homepage_links2 if x not in junk_links2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.foxnews.com/media/chris-matthews-resignation-from-msnbc-hastened-by-series-of-blunders', 'https://www.foxnews.com/politics/warren-huddles-with-advisers-as-progressive-pressure-for-her-to-drop-out-mounts', 'https://www.foxnews.com/politics/supreme-court-at-apparent-odds-over-key-abortion-case-over-clinic-access-restrictions', 'https://www.foxnews.com/politics/fox-news-poll-sanders-knocks-biden-out-of-first-majority-thinks-trump-wins', 'https://www.foxnews.com/politics/issa-mounts-a-comeback-in-california', 'https://www.foxnews.com/politics/biden-campaign-hits-back-at-sanders-ad-showing-obama-praise', 'https://www.foxnews.com/media/francis-tarlov-joe-biden-trump-clinton', 'https://www.foxnews.com/politics/pence-says-passengers-on-flights-from-italy-and-south-korea-will-be-screened-multiple-times-for-coronavirus', 'https://www.foxnews.com/politics/mike-bloomberg-suspends-presidential-campaign-after-super-tuesday-show', 'https://www.foxnews.com/politics/aoc-aligned-progressive-candidates-fall-flat-in-super-tuesday-contests', 'https://www.foxnews.com/politics/texas-congressional-race-results', 'https://www.foxnews.com/politics/super-tuesday-results-where-the-2020-democratic-candidates-stand', 'https://www.foxnews.com/media/biden-shocks-the-pundits-again-with-surprisingly-strong-super-tuesday', 'https://www.foxnews.com/media/bidens-super-tuesday-challenge-after-defying-the-medias-obituaries', 'https://www.foxnews.com/politics/ex-cuban-prisoner-alan-gross-accuses-sanders-of-praising-cuba-during-visit', 'https://www.foxnews.com/media/markets-sigh-relief-bernie-falls-behind-biden', 'https://www.foxnews.com/politics/fox-news-poll-capitalism-socialism-bernie-sanders', 'https://www.foxnews.com/politics/biden-thumps-bernie', 'https://www.foxnews.com/opinion/newt-gingrich-50-hours-that-changed-the-2020-democratic-presidential-race', 'https://www.foxnews.com/politics/fox-news-voter-analysis-biden-sanders-emerge-from-dem-pack-on-super-tuesday', 'https://www.foxnews.com/politics/trump-calls-warren-selfish-for-staying-in-2020-democratic-contest', 'https://www.foxnews.com/politics/fox-news-poll-trump-economy-failed-to-unify']\n"
     ]
    }
   ],
   "source": [
    "# add https://www.foxnews.com to links that don't have this\n",
    "# create new list for prepared links\n",
    "hp_links2 = []\n",
    "\n",
    "for item in homepage_links2:\n",
    "    new_item = 'https://www.foxnews.com' + item\n",
    "    hp_links2.append(new_item)\n",
    "\n",
    "print(hp_links2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: check for duplicates to set of existing URLs to make sure we only pull data for new ones\n",
    "    # import full dataset in\n",
    "    # remove urls in homepage_links3 that are already included in the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get article text and other relevent data from new articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas dataframe where all of the retrieved data will be stored\n",
    "#article_data2 = pd.DataFrame()\n",
    "\n",
    "#article_data2['headline'] = []\n",
    "#article_data2['date_published'] = []\n",
    "#article_data2['date_modified'] = []\n",
    "#article_data2['description'] = []\n",
    "#article_data2['author'] = []\n",
    "#article_data2['url'] = []\n",
    "\n",
    "#export empty df to file\n",
    "#article_data2.to_csv('Fox_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "headline = []\n",
    "date_published = []\n",
    "date_modified = []\n",
    "description = []\n",
    "author = []\n",
    "url = []\n",
    "\n",
    "for link in hp_links2:\n",
    "    # load the HTML content using requests and save into a variable\n",
    "    r2_article = requests.get(link)\n",
    "    article2 = r2_article.content\n",
    "\n",
    "    # create a soups to allow BeautifulSoup to work\n",
    "    article_soup2 = BeautifulSoup(article2, 'html.parser')\n",
    "\n",
    "    # get article text\n",
    "    article_text = article_soup2.find(\"body\").get_text()\n",
    "    text.append(text)\n",
    "    \n",
    "    # retrieve article specific metadata\n",
    "    metadata2 = article_soup2.find_all(\"script\")[2].get_text()\n",
    "    metadata2 = metadata2.split(\",\")\n",
    "\n",
    "    for item in metadata2:\n",
    "        if 'headline' in item:\n",
    "            headline.append(item)\n",
    "        elif 'datePublished' in item:\n",
    "            date_published.append(item)\n",
    "        elif 'dateModified' in item:\n",
    "            date_modified.append(item)\n",
    "        elif 'description' in item:\n",
    "            description.append(item)\n",
    "        elif 'name' in item and 'Fox News' not in item:\n",
    "            author.append(item)\n",
    "        elif 'mainEntityOfPage' in item:\n",
    "            url.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 22\n",
      "headline 22\n",
      "date_published 22\n",
      "date_modified 22\n",
      "description 22\n",
      "author 21\n",
      "url 22\n"
     ]
    }
   ],
   "source": [
    "print('text', len(text))\n",
    "print('headline', len(headline))\n",
    "print('date_published', len(date_published))\n",
    "print('date_modified', len(date_modified))\n",
    "print('description', len(description))\n",
    "print('author', len(author))\n",
    "print('url', len(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-931919f5c54e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marticle_data2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mheadline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date_published'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdate_published\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date_modified'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdate_modified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'description'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'author'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    409\u001b[0m             )\n\u001b[1;32m    410\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         ]\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "#article_data2 = pd.DataFrame({'text':text,'title':headline, 'date_published':date_published, 'date_modified':date_modified, 'description':description, 'author':author, 'url':url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collection of all responses\n",
    "all_articles2 = pd.read_csv(\"Fox_Data.csv\", index_col=[0])\n",
    "\n",
    "# merge new increment of data to the csv\n",
    "all_articles2 = article_data2.append(article_data2, ignore_index=True)\n",
    "\n",
    "#export with new increment to save\n",
    "all_articles.to_csv('Fox_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<meta content=\"Dana Blanton\" data-hid=\"dc.creator\" data-n-head=\"true\" name=\"dc.creator\" scheme=\"dcterms.creator\"/>\n"
     ]
    }
   ],
   "source": [
    "# another spot the author is located just in case\n",
    "# test = article_soup3.find_all(\"meta\")[17]\n",
    "#print(yay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Wall Street Journal - Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. New York Times - Liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "nyt_request = requests.get('https://www.nytimes.com/section/politics')\n",
    "nyt_homepage = nyt_request.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup \n",
    "nyt_soup = BeautifulSoup(nyt_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homepage URLs\n",
    "nyt_tags_home = nyt_soup.find_all('h2', class_=\"css-l2vidh e4e4i5l1\")\n",
    "\n",
    "# archive URLs\n",
    "nyt_tags_archive = nyt_soup.find_all('div', class_='css-1l4spti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup \n",
    "nyt_links = []\n",
    "nyt_titles = []\n",
    "nyt_dates = []\n",
    "nyt_contents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homepage articles\n",
    "for n in np.arange(0, len(nyt_tags_home)):\n",
    "\n",
    "    # get article link\n",
    "    link = nyt_tags_home[n].find('a')['href']\n",
    "    link = \"https://www.nytimes.com\" + link\n",
    "    nyt_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = nyt_tags_home[n].find('a').get_text()\n",
    "    nyt_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.time.attrs['datetime']\n",
    "    date = date[:-15]\n",
    "    nyt_dates.append(date)\n",
    "    \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', class_='css-53u6y8')\n",
    "    x = body[0].find_all('p')\n",
    "    \n",
    "    # combine paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        list_paragraphs.append(paragraph)\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "        \n",
    "    nyt_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# archive articles\n",
    "for n in np.arange(0, len(nyt_tags_archive)):\n",
    "\n",
    "    # get article link\n",
    "    link = nyt_tags_archive[n].find('a')['href']\n",
    "    link = \"https://www.nytimes.com\" + link\n",
    "    nyt_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = nyt_tags_archive[n].find('a').get_text()\n",
    "    nyt_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.time.attrs['datetime']\n",
    "    date = date[:-15]\n",
    "    nyt_dates.append(date)\n",
    "        \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', class_='css-53u6y8')\n",
    "    x = body[0].find_all('p')\n",
    "    \n",
    "    # combine paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        list_paragraphs.append(paragraph)\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "        \n",
    "    nyt_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembling data\n",
    "nyt_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'new_york_times',\n",
    "    'date': nyt_dates,\n",
    "    'link': nyt_links,\n",
    "    'article_title': nyt_titles,\n",
    "    'article_text': nyt_contents \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WEST PALM BEACH, Fla. — President Trump on Fri...</td>\n",
       "      <td>Trump Names Mark Meadows Chief of Staff, Ousti...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.nytimes.com/2020/03/06/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>President Trump claimed again on Friday that a...</td>\n",
       "      <td>With Test Kits in Short Supply, Health Officia...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.nytimes.com/2020/03/06/health/test...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bernie Sanders was several takes into a video ...</td>\n",
       "      <td>The Bernie Sanders Personality Test</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>https://www.nytimes.com/2020/03/06/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joseph R. Biden Jr.’s campaign organization in...</td>\n",
       "      <td>Joe Biden Has Had Flimsy Organization. It Hasn...</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>https://www.nytimes.com/2020/03/06/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WASHINGTON — After weeks of conflicting signal...</td>\n",
       "      <td>Miscommunication, Confusion and Fear Mar White...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.nytimes.com/2020/03/07/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WASHINGTON — Erik Prince, the security contrac...</td>\n",
       "      <td>Erik Prince Recruits Ex-Spies to Help Infiltra...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.nytimes.com/2020/03/07/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lucio Delgado was excited when he went to the ...</td>\n",
       "      <td>With No Braille Option, a Blind Man Failed His...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.nytimes.com/2020/03/07/us/citizens...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In just seven days, the Democratic race has ch...</td>\n",
       "      <td>Biden Is Back: This Week in the 2020 RaceJosep...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.nytimes.com/2020/03/07/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MADISON, Wis. — Debt has dogged Brian Michelz ...</td>\n",
       "      <td>A Sanders Voter, Weary of Debt at 29: ‘I Have ...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.nytimes.com/2020/03/07/us/bernie-s...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>When Senator Elizabeth Warren dropped out of t...</td>\n",
       "      <td>The Hidden Venmo Economy of Campaign Staffers ...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.nytimes.com/2020/03/07/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WASHINGTON — Attorney General William P. Barr ...</td>\n",
       "      <td>News AnalysisBarr Increasingly Appears Focused...</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>https://www.nytimes.com/2020/03/06/us/barr-mue...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WASHINGTON — Vice President Mike Pence has lon...</td>\n",
       "      <td>Pence, a Loyalist Tapped for Coronavirus Effor...</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>https://www.nytimes.com/2020/03/06/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The news that Senator Elizabeth Warren was exi...</td>\n",
       "      <td>‘America Needs Her’: Readers React to Elizabet...</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>https://www.nytimes.com/2020/03/06/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DETROIT — Calibrating his approach for a tough...</td>\n",
       "      <td>Sanders Continues Attacks on Trade but Concede...</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>https://www.nytimes.com/2020/03/06/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         article_text  \\\n",
       "0   WEST PALM BEACH, Fla. — President Trump on Fri...   \n",
       "1   President Trump claimed again on Friday that a...   \n",
       "2   Bernie Sanders was several takes into a video ...   \n",
       "3   Joseph R. Biden Jr.’s campaign organization in...   \n",
       "4   WASHINGTON — After weeks of conflicting signal...   \n",
       "5   WASHINGTON — Erik Prince, the security contrac...   \n",
       "6   Lucio Delgado was excited when he went to the ...   \n",
       "7   In just seven days, the Democratic race has ch...   \n",
       "8   MADISON, Wis. — Debt has dogged Brian Michelz ...   \n",
       "9   When Senator Elizabeth Warren dropped out of t...   \n",
       "10  WASHINGTON — Attorney General William P. Barr ...   \n",
       "11  WASHINGTON — Vice President Mike Pence has lon...   \n",
       "12  The news that Senator Elizabeth Warren was exi...   \n",
       "13  DETROIT — Calibrating his approach for a tough...   \n",
       "\n",
       "                                        article_title        date  \\\n",
       "0   Trump Names Mark Meadows Chief of Staff, Ousti...  2020-03-07   \n",
       "1   With Test Kits in Short Supply, Health Officia...  2020-03-07   \n",
       "2                 The Bernie Sanders Personality Test  2020-03-06   \n",
       "3   Joe Biden Has Had Flimsy Organization. It Hasn...  2020-03-06   \n",
       "4   Miscommunication, Confusion and Fear Mar White...  2020-03-07   \n",
       "5   Erik Prince Recruits Ex-Spies to Help Infiltra...  2020-03-07   \n",
       "6   With No Braille Option, a Blind Man Failed His...  2020-03-07   \n",
       "7   Biden Is Back: This Week in the 2020 RaceJosep...  2020-03-07   \n",
       "8   A Sanders Voter, Weary of Debt at 29: ‘I Have ...  2020-03-07   \n",
       "9   The Hidden Venmo Economy of Campaign Staffers ...  2020-03-07   \n",
       "10  News AnalysisBarr Increasingly Appears Focused...  2020-03-06   \n",
       "11  Pence, a Loyalist Tapped for Coronavirus Effor...  2020-03-06   \n",
       "12  ‘America Needs Her’: Readers React to Elizabet...  2020-03-06   \n",
       "13  Sanders Continues Attacks on Trade but Concede...  2020-03-06   \n",
       "\n",
       "                                                 link       publisher  \n",
       "0   https://www.nytimes.com/2020/03/06/us/politics...  new_york_times  \n",
       "1   https://www.nytimes.com/2020/03/06/health/test...  new_york_times  \n",
       "2   https://www.nytimes.com/2020/03/06/us/politics...  new_york_times  \n",
       "3   https://www.nytimes.com/2020/03/06/us/politics...  new_york_times  \n",
       "4   https://www.nytimes.com/2020/03/07/us/politics...  new_york_times  \n",
       "5   https://www.nytimes.com/2020/03/07/us/politics...  new_york_times  \n",
       "6   https://www.nytimes.com/2020/03/07/us/citizens...  new_york_times  \n",
       "7   https://www.nytimes.com/2020/03/07/us/politics...  new_york_times  \n",
       "8   https://www.nytimes.com/2020/03/07/us/bernie-s...  new_york_times  \n",
       "9   https://www.nytimes.com/2020/03/07/us/politics...  new_york_times  \n",
       "10  https://www.nytimes.com/2020/03/06/us/barr-mue...  new_york_times  \n",
       "11  https://www.nytimes.com/2020/03/06/us/politics...  new_york_times  \n",
       "12  https://www.nytimes.com/2020/03/06/us/politics...  new_york_times  \n",
       "13  https://www.nytimes.com/2020/03/06/us/politics...  new_york_times  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it looks nice\n",
    "nyt_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in old data\n",
    "old_nyt_data = pd.read_csv('data/nyt_data.csv')\n",
    "\n",
    "# append new data\n",
    "nyt_data = old_nyt_data.append(nyt_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "nyt_data.to_csv(\"data/nyt_data.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
