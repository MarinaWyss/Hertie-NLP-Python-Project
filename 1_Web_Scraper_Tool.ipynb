{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper Tool for 5 US Media Outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import UnicodeDammit\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Breitbart - Very Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "breitbart_request = requests.get('https://www.breitbart.com/politics/')\n",
    "breitbart_homepage = breitbart_request.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup \n",
    "breitbart_soup = BeautifulSoup(breitbart_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# locate article URLs\n",
    "breitbart_tags = breitbart_soup.find_all('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_articles = 30\n",
    "\n",
    "# get article titles, content, and links\n",
    "breitbart_links = []\n",
    "breitbart_titles = []\n",
    "breitbart_dates = []\n",
    "breitbart_contents = []\n",
    "\n",
    "for n in np.arange(0, number_of_articles):\n",
    "\n",
    "    # get article link\n",
    "    link = breitbart_tags[n].find('a')['href']\n",
    "    link = \"https://www.breitbart.com\" + link\n",
    "    breitbart_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = breitbart_tags[n].find('a').get_text()\n",
    "    breitbart_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.time.attrs['datetime']\n",
    "    date = date[:-10]\n",
    "    breitbart_dates.append(date)\n",
    "    \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', class_='entry-content')\n",
    "    x = body[0].find_all('p')\n",
    "    \n",
    "    # combine paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        list_paragraphs.append(paragraph)\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "        \n",
    "    breitbart_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembling data\n",
    "breitbart_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'Breitbart',\n",
    "    'date': breitbart_dates,\n",
    "    'link': breitbart_links,\n",
    "    'article_title': breitbart_titles,\n",
    "    'article_text': breitbart_contents \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A group of Conservative party grandees will se...</td>\n",
       "      <td>Tories Rebel over Huawei: As ‘Ridiculous’ as G...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/europe/2020/03/07/to...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greece has accused the Turkish government of s...</td>\n",
       "      <td>Greece Denounces ‘Fake News’ as Turkey Claims ...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/europe/2020/03/07/gr...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dramatic pictures and video are emerging of fi...</td>\n",
       "      <td>PICTURES: Greek Border in Flames as Migrants K...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/europe/2020/03/07/pi...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finland’s millennial feminist-led government f...</td>\n",
       "      <td>Finland’s Millennial Feminist Govt to Help Gre...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/europe/2020/03/07/fi...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A total of 76 per cent of the Greek public sup...</td>\n",
       "      <td>Nearly 8 in 10 Greeks Support Government’s Bor...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/europe/2020/03/07/ne...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_text  \\\n",
       "0  A group of Conservative party grandees will se...   \n",
       "1  Greece has accused the Turkish government of s...   \n",
       "2  Dramatic pictures and video are emerging of fi...   \n",
       "3  Finland’s millennial feminist-led government f...   \n",
       "4  A total of 76 per cent of the Greek public sup...   \n",
       "\n",
       "                                       article_title        date  \\\n",
       "0  Tories Rebel over Huawei: As ‘Ridiculous’ as G...  2020-03-07   \n",
       "1  Greece Denounces ‘Fake News’ as Turkey Claims ...  2020-03-07   \n",
       "2  PICTURES: Greek Border in Flames as Migrants K...  2020-03-07   \n",
       "3  Finland’s Millennial Feminist Govt to Help Gre...  2020-03-07   \n",
       "4  Nearly 8 in 10 Greeks Support Government’s Bor...  2020-03-07   \n",
       "\n",
       "                                                link  publisher  \n",
       "0  https://www.breitbart.com/europe/2020/03/07/to...  Breitbart  \n",
       "1  https://www.breitbart.com/europe/2020/03/07/gr...  Breitbart  \n",
       "2  https://www.breitbart.com/europe/2020/03/07/pi...  Breitbart  \n",
       "3  https://www.breitbart.com/europe/2020/03/07/fi...  Breitbart  \n",
       "4  https://www.breitbart.com/europe/2020/03/07/ne...  Breitbart  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it looks nice\n",
    "breitbart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in old data\n",
    "old_breitbart_data = pd.read_csv('data/breitbart_data.csv')\n",
    "\n",
    "# append new data\n",
    "breitbart_data = old_breitbart_data.append(breitbart_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "breitbart_data.to_csv(\"data/breitbart_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fox - Conservative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get links from the Fox Politics homepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "fox_requests = requests.get('https://www.foxnews.com/politics')\n",
    "fox_homepage = fox_requests.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a soup to allow BeautifulSoup to work\n",
    "fox_soup = BeautifulSoup(fox_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate article links\n",
    "fox_tags = fox_soup.find_all('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_articles = 30\n",
    "\n",
    "fox_links = []\n",
    "\n",
    "# get homepage article links\n",
    "for n in np.arange(0, number_of_articles):\n",
    "    link = fox_tags[n].find('a')\n",
    "    link = link.get('href')\n",
    "    link = \"https://foxnews.com\" + link\n",
    "    fox_links.append(link)\n",
    "    fox_links = [x for x in fox_links if \"/v/\" not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_text = []\n",
    "fox_titles = []\n",
    "fox_dates = []\n",
    "\n",
    "# prep for article content\n",
    "for link in fox_links:\n",
    "    fox_article_request = requests.get(link)\n",
    "    fox_article = fox_article_request.content\n",
    "    fox_article_soup = BeautifulSoup(fox_article, 'html.parser')\n",
    "    \n",
    "    # get article metadata\n",
    "    fox_metadata = fox_article_soup.find_all('script')[2].get_text()\n",
    "    fox_metadata = fox_metadata.split(\",\")\n",
    "    \n",
    "    for item in fox_metadata:\n",
    "\n",
    "        # get article title\n",
    "        if 'headline' in item:\n",
    "            item = item.replace('\\n',\"\")\n",
    "            item = item.replace('headline', \"\")\n",
    "            item = item.replace(':', \"\")\n",
    "            item = item.replace('\"', '')\n",
    "            fox_titles.append(item)\n",
    "        \n",
    "        # get article date\n",
    "        elif 'datePublished' in item:\n",
    "            item = item.replace('\\n',\"\")\n",
    "            item = item.replace('datePublished', \"\")\n",
    "            item = item.replace(':', \"\")\n",
    "            item = item.replace('\"', '')\n",
    "            fox_dates.append(item)\n",
    "    \n",
    "    # get article text\n",
    "    body = fox_article_soup.find_all('div')\n",
    "    x = body[0].find_all('p')\n",
    "    \n",
    "    # combine paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        paragraph = paragraph.replace('\\n',\"\")\n",
    "        list_paragraphs.append(paragraph)\n",
    "        \n",
    "        # removing copyright info and newsletter junk from the article\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "        final_article = final_article.replace(\"This material may not be published, broadcast, rewritten, or redistributed. ©2020 FOX News Network, LLC. All rights reserved. All market data delayed 20 minutes.\", \" \")\n",
    "        final_article = final_article.replace(\"This material may not be published, broadcast, rewritten,\", \" \")\n",
    "        final_article = final_article.replace(\"or redistributed. ©2020 FOX News Network, LLC. All rights reserved.\", \" \")\n",
    "        final_article = final_article.replace(\"All market data delayed 20 minutes.\", \" \")\n",
    "        final_article = final_article.replace(\"Get all the stories you need-to-know from the most powerful name in news delivered first thing every morning to your inbox Subscribed You've successfully subscribed to this newsletter!\", \" \")\n",
    "    fox_text.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-07T154057-0500</td>\n",
       "      <td>https://foxnews.com/politics/pence-coronavirus...</td>\n",
       "      <td>Pence calls for 'whole of America' ap...</td>\n",
       "      <td>VP Pence meets with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-06T211054-0500</td>\n",
       "      <td>https://foxnews.com/politics/house-prepares-te...</td>\n",
       "      <td>House prepares for telework scenarios...</td>\n",
       "      <td>Fox News Flash top h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-07T131303-0500</td>\n",
       "      <td>https://foxnews.com/politics/sanders-biden-ent...</td>\n",
       "      <td>Sanders says Biden can’t ‘generate en...</td>\n",
       "      <td>Former Vice Presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-07T154057-0500</td>\n",
       "      <td>https://foxnews.com/politics/pence-coronavirus...</td>\n",
       "      <td>Pence calls for 'whole of America' ap...</td>\n",
       "      <td>VP Pence meets with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-07T131303-0500</td>\n",
       "      <td>https://foxnews.com/politics/sanders-biden-ent...</td>\n",
       "      <td>Sanders says Biden can’t ‘generate en...</td>\n",
       "      <td>Former Vice Presiden...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publisher                             date  \\\n",
       "0       Fox           2020-03-07T154057-0500   \n",
       "1       Fox           2020-03-06T211054-0500   \n",
       "2       Fox           2020-03-07T131303-0500   \n",
       "3       Fox           2020-03-07T154057-0500   \n",
       "4       Fox           2020-03-07T131303-0500   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://foxnews.com/politics/pence-coronavirus...   \n",
       "1  https://foxnews.com/politics/house-prepares-te...   \n",
       "2  https://foxnews.com/politics/sanders-biden-ent...   \n",
       "3  https://foxnews.com/politics/pence-coronavirus...   \n",
       "4  https://foxnews.com/politics/sanders-biden-ent...   \n",
       "\n",
       "                                       article_title  \\\n",
       "0           Pence calls for 'whole of America' ap...   \n",
       "1           House prepares for telework scenarios...   \n",
       "2           Sanders says Biden can’t ‘generate en...   \n",
       "3           Pence calls for 'whole of America' ap...   \n",
       "4           Sanders says Biden can’t ‘generate en...   \n",
       "\n",
       "                                        article_text  \n",
       "0                            VP Pence meets with ...  \n",
       "1                            Fox News Flash top h...  \n",
       "2                            Former Vice Presiden...  \n",
       "3                            VP Pence meets with ...  \n",
       "4                            Former Vice Presiden...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join fox data\n",
    "fox_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'Fox',\n",
    "    'date': fox_dates,\n",
    "    'link': fox_links,\n",
    "    'article_title': fox_titles,\n",
    "    'article_text': fox_text \n",
    "})\n",
    "\n",
    "fox_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_data.to_csv(\"data/fox_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in old data\n",
    "old_fox_data = pd.read_csv('data/fox_data.csv')\n",
    "\n",
    "# append new data\n",
    "fox_data = old_fox_data.append(fox_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "fox_data.to_csv(\"data/fox_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Wall Street Journal - Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
