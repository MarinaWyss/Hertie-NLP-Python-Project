{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper Tool for 5 US Media Outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import UnicodeDammit\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Breitbart - Very Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "breitbart_request = requests.get('https://www.breitbart.com/politics/')\n",
    "breitbart_homepage = breitbart_request.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup \n",
    "breitbart_soup = BeautifulSoup(breitbart_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# locate article URLs\n",
    "breitbart_tags = breitbart_soup.find_all('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "number_of_articles = min(len(breitbart_tags), 30)\n",
    "\n",
    "breitbart_links = []\n",
    "breitbart_titles = []\n",
    "breitbart_dates = []\n",
    "breitbart_contents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get article titles, content, and links\n",
    "for n in np.arange(0, number_of_articles):\n",
    "\n",
    "    # get article link\n",
    "    link = breitbart_tags[n].find('a')['href']\n",
    "    link = \"https://www.breitbart.com\" + link\n",
    "    breitbart_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = breitbart_tags[n].find('a').get_text()\n",
    "    breitbart_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.time.attrs['datetime']\n",
    "    date = date[:-10]\n",
    "    breitbart_dates.append(date)\n",
    "    \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', class_='entry-content')\n",
    "    x = body[0].find_all('p')\n",
    "    \n",
    "    # combine paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        list_paragraphs.append(paragraph)\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "        \n",
    "    breitbart_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembling data\n",
    "breitbart_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'Breitbart',\n",
    "    'date': breitbart_dates,\n",
    "    'link': breitbart_links,\n",
    "    'article_title': breitbart_titles,\n",
    "    'article_text': breitbart_contents \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>https://www.breitbart.com/politics/2020/03/13/...</td>\n",
       "      <td>Police: Andrew Gillum Involved in Suspected Cr...</td>\n",
       "      <td>Failed Florida gubernatorial candidate Andrew ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/13/dr-...</td>\n",
       "      <td>Dr. Fauci on Coronavirus: ‘It Absolutely Came ...</td>\n",
       "      <td>During a Friday interview on “Fox &amp; Friends,” ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>https://www.breitbart.com/politics/2020/03/13/...</td>\n",
       "      <td>Job Creators Network Runs ‘Small Business Is T...</td>\n",
       "      <td>Job Creators Network (JCN) ran a full-page ad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>https://www.breitbart.com/economy/2020/03/13/c...</td>\n",
       "      <td>Coronavirus: Mnuchin Floats Pause on Student L...</td>\n",
       "      <td>Appearing Friday on CNBC, Treasury Secretary S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>https://www.breitbart.com/latin-america/2020/0...</td>\n",
       "      <td>Update: Brazil’s Jair Bolsonaro Tests Negative...</td>\n",
       "      <td>Update: Brazilian President Jair Bolsonaro say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publisher        date                                               link  \\\n",
       "0  Breitbart  2020-03-13  https://www.breitbart.com/politics/2020/03/13/...   \n",
       "1  Breitbart  2020-03-13  https://www.breitbart.com/clips/2020/03/13/dr-...   \n",
       "2  Breitbart  2020-03-13  https://www.breitbart.com/politics/2020/03/13/...   \n",
       "3  Breitbart  2020-03-13  https://www.breitbart.com/economy/2020/03/13/c...   \n",
       "4  Breitbart  2020-03-13  https://www.breitbart.com/latin-america/2020/0...   \n",
       "\n",
       "                                       article_title  \\\n",
       "0  Police: Andrew Gillum Involved in Suspected Cr...   \n",
       "1  Dr. Fauci on Coronavirus: ‘It Absolutely Came ...   \n",
       "2  Job Creators Network Runs ‘Small Business Is T...   \n",
       "3  Coronavirus: Mnuchin Floats Pause on Student L...   \n",
       "4  Update: Brazil’s Jair Bolsonaro Tests Negative...   \n",
       "\n",
       "                                        article_text  \n",
       "0  Failed Florida gubernatorial candidate Andrew ...  \n",
       "1  During a Friday interview on “Fox & Friends,” ...  \n",
       "2  Job Creators Network (JCN) ran a full-page ad ...  \n",
       "3  Appearing Friday on CNBC, Treasury Secretary S...  \n",
       "4  Update: Brazilian President Jair Bolsonaro say...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it looks nice\n",
    "breitbart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entries in old data: 150\n",
      "total number of entries in new data: 180\n"
     ]
    }
   ],
   "source": [
    "# read in old data\n",
    "old_breitbart_data = pd.read_csv('data/breitbart_data.csv')\n",
    "num_old = len(old_breitbart_data)\n",
    "\n",
    "# append new data\n",
    "breitbart_data = old_breitbart_data.append(breitbart_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "breitbart_data.to_csv(\"data/breitbart_data.csv\", index = False)\n",
    "num_now = len(breitbart_data)\n",
    "\n",
    "print(\"number of entries in old data: {}\".format(num_old))\n",
    "print(\"total number of entries in new data: {}\".format(num_now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fox - Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "fox_requests = requests.get('https://www.foxnews.com/politics')\n",
    "fox_homepage = fox_requests.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a soup to allow BeautifulSoup to work\n",
    "fox_soup = BeautifulSoup(fox_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate article links\n",
    "fox_tags = fox_soup.find_all('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "fox_links = []\n",
    "fox_text = []\n",
    "fox_titles = []\n",
    "fox_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_articles = 30\n",
    "\n",
    "# get homepage article links\n",
    "for n in np.arange(0, number_of_articles):\n",
    "    link = fox_tags[n].find('a')\n",
    "    link = link.get('href')\n",
    "    link = \"https://foxnews.com\" + link\n",
    "    fox_links.append(link)\n",
    "    fox_links = [x for x in fox_links if \"/v/\" not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep for article content\n",
    "for link in fox_links:\n",
    "    fox_article_request = requests.get(link)\n",
    "    fox_article = fox_article_request.content\n",
    "    fox_article_soup = BeautifulSoup(fox_article, 'html.parser')\n",
    "    \n",
    "    # get article metadata\n",
    "    fox_metadata = fox_article_soup.find_all('script')[2].get_text()\n",
    "    fox_metadata = fox_metadata.split(\",\")\n",
    "    \n",
    "    for item in fox_metadata:\n",
    "\n",
    "        # get article title\n",
    "        if 'headline' in item:\n",
    "            item = item.replace('\\n',\"\")\n",
    "            item = item.replace('headline', \"\")\n",
    "            item = item.replace(':', \"\")\n",
    "            item = item.replace('\"', '')\n",
    "            fox_titles.append(item)\n",
    "        \n",
    "        # get article date\n",
    "        elif 'datePublished' in item:\n",
    "            item = item.replace('\\n',\"\")\n",
    "            item = item.replace('datePublished', \"\")\n",
    "            item = item.replace(':', \"\")\n",
    "            item = item.replace('\"', '')\n",
    "            fox_dates.append(item)\n",
    "    \n",
    "    # get article text\n",
    "    body = fox_article_soup.find_all('div')\n",
    "    x = body[0].find_all('p')\n",
    "    \n",
    "    # combine paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        paragraph = paragraph.replace('\\n',\"\")\n",
    "        list_paragraphs.append(paragraph)\n",
    "        \n",
    "        # removing copyright info and newsletter junk from the article\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "        final_article = final_article.replace(\"This material may not be published, broadcast, rewritten, or redistributed. ©2020 FOX News Network, LLC. All rights reserved. All market data delayed 20 minutes.\", \" \")\n",
    "        final_article = final_article.replace(\"This material may not be published, broadcast, rewritten,\", \" \")\n",
    "        final_article = final_article.replace(\"or redistributed. ©2020 FOX News Network, LLC. All rights reserved.\", \" \")\n",
    "        final_article = final_article.replace(\"All market data delayed 20 minutes.\", \" \")\n",
    "        final_article = final_article.replace(\"Get all the stories you need-to-know from the most powerful name in news delivered first thing every morning to your inbox Subscribed You've successfully subscribed to this newsletter!\", \" \")\n",
    "    fox_text.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-13T062329-0400</td>\n",
       "      <td>https://foxnews.com/politics/pelosi-telegraphs...</td>\n",
       "      <td>Pelosi telegraphs third coronavirus f...</td>\n",
       "      <td>Reaction and analysi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-13T082906-0400</td>\n",
       "      <td>https://foxnews.com/politics/dem-rep-katie-por...</td>\n",
       "      <td>Dem Rep. Katie Porter</td>\n",
       "      <td>Rep. Michael C. Burg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-13T083949-0400</td>\n",
       "      <td>https://foxnews.com/politics/gop-senator-subpo...</td>\n",
       "      <td>GOP senator plans to subpoena consult...</td>\n",
       "      <td>GOP senators ramp up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-13T094443-0400</td>\n",
       "      <td>https://foxnews.com/politics/joe-bidens-corona...</td>\n",
       "      <td>Joe Biden's coronavirus plan What's i...</td>\n",
       "      <td>Democratic president...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-13T110950-0400</td>\n",
       "      <td>https://foxnews.com/politics/trump-to-brief-pr...</td>\n",
       "      <td>Trump to hold press conference on cor...</td>\n",
       "      <td>President Trump says...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publisher                             date  \\\n",
       "0       Fox           2020-03-13T062329-0400   \n",
       "1       Fox           2020-03-13T082906-0400   \n",
       "2       Fox           2020-03-13T083949-0400   \n",
       "3       Fox           2020-03-13T094443-0400   \n",
       "4       Fox           2020-03-13T110950-0400   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://foxnews.com/politics/pelosi-telegraphs...   \n",
       "1  https://foxnews.com/politics/dem-rep-katie-por...   \n",
       "2  https://foxnews.com/politics/gop-senator-subpo...   \n",
       "3  https://foxnews.com/politics/joe-bidens-corona...   \n",
       "4  https://foxnews.com/politics/trump-to-brief-pr...   \n",
       "\n",
       "                                       article_title  \\\n",
       "0           Pelosi telegraphs third coronavirus f...   \n",
       "1                              Dem Rep. Katie Porter   \n",
       "2           GOP senator plans to subpoena consult...   \n",
       "3           Joe Biden's coronavirus plan What's i...   \n",
       "4           Trump to hold press conference on cor...   \n",
       "\n",
       "                                        article_text  \n",
       "0                            Reaction and analysi...  \n",
       "1                            Rep. Michael C. Burg...  \n",
       "2                            GOP senators ramp up...  \n",
       "3                            Democratic president...  \n",
       "4                            President Trump says...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join fox data\n",
    "fox_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'Fox',\n",
    "    'date': fox_dates,\n",
    "    'link': fox_links,\n",
    "    'article_title': fox_titles,\n",
    "    'article_text': fox_text \n",
    "})\n",
    "\n",
    "fox_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in old data\n",
    "old_fox_data = pd.read_csv('data/fox_data.csv')\n",
    "num_old = len(old_fox_data)\n",
    "\n",
    "# append new data\n",
    "fox_data = old_fox_data.append(fox_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "fox_data.to_csv(\"data/fox_data.csv\", index = False)\n",
    "num_now = len(fox_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entries in old data: 67\n",
      "total number of entries in new data: 81\n",
      "difference: 14\n"
     ]
    }
   ],
   "source": [
    "# see number of articles\n",
    "print(\"number of entries in old data: {}\".format(num_old))\n",
    "print(\"total number of entries in new data: {}\".format(num_now))\n",
    "print(\"difference: {}\".format(num_now-num_old))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Associated Press - Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "ap_requests = requests.get('https://apnews.com/apf-politics')\n",
    "ap_homepage = ap_requests.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a soup to allow BeautifulSoup to work\n",
    "ap_soup = BeautifulSoup(ap_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate articles\n",
    "ap_tags = ap_soup.find_all('a', class_=\"Component-headline-0-2-105\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "number_of_articles = min(len(ap_tags), 30)\n",
    "\n",
    "ap_links = []\n",
    "ap_text = []\n",
    "ap_titles = []\n",
    "ap_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get homepage article links\n",
    "for link in ap_tags:\n",
    "    link = link.get('href')\n",
    "    link = \"https://apnews.com\" + link\n",
    "    ap_links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep for article content\n",
    "for link in ap_links:\n",
    "    ap_article_request = requests.get(link)\n",
    "    ap_article = ap_article_request.content\n",
    "    ap_article_soup = BeautifulSoup(ap_article, 'html.parser')\n",
    "    \n",
    "    # article titles\n",
    "    title = ap_article_soup.find_all('meta')[14]\n",
    "    title = title['content']\n",
    "    ap_titles.append(title)\n",
    "    \n",
    "    # article date\n",
    "    date = ap_article_soup.find_all('meta')[24]\n",
    "    date = date['content']\n",
    "    ap_dates.append(date)\n",
    "    \n",
    "    # article content: <div class=\"Article\" data-key=Article.\n",
    "    body = ap_article_soup.find_all('div')\n",
    "    x = body[0].find_all('p')\n",
    "\n",
    "    # combine paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        paragraph = paragraph.replace('\\n',\"\")\n",
    "        paragraph = paragraph.replace('CHICAGO (AP) -',\"\")\n",
    "        paragraph = paragraph.replace('DETROIT (AP) -',\"\")\n",
    "        paragraph = paragraph.replace('WASHINGTON (AP) -',\"\")\n",
    "        paragraph = paragraph.replace('___ Catch up on the 2020 election campaign with AP experts on our weekly politics podcast, “Ground Game.',\"\")\n",
    "        list_paragraphs.append(paragraph)\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "    ap_text.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AP</td>\n",
       "      <td>2020-03-13T12:37:22Z</td>\n",
       "      <td>https://apnews.com/83b0c8e168548fd453b0c177dd1...</td>\n",
       "      <td>Pelosi, White House near agreement on coronavi...</td>\n",
       "      <td>WASHINGTON (AP) — House Speaker Nancy Pelosi a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>2020-03-13T15:22:24Z</td>\n",
       "      <td>https://apnews.com/663e745a80358c042786d2a5624...</td>\n",
       "      <td>Trump to hold news conference as he seeks to c...</td>\n",
       "      <td>WASHINGTON (AP) — President Donald Trump will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AP</td>\n",
       "      <td>2020-03-13T13:13:09Z</td>\n",
       "      <td>https://apnews.com/d7cb8610b50a2e79ce1a72929f2...</td>\n",
       "      <td>Trump administration: $1.3M for fast virus tes...</td>\n",
       "      <td>President Donald Trump’s administration announ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AP</td>\n",
       "      <td>2020-03-13T12:00:17Z</td>\n",
       "      <td>https://apnews.com/0c26235718a02157e5831933f57...</td>\n",
       "      <td>Chairwoman of Congressional Black Caucus endor...</td>\n",
       "      <td>The chairwoman of the Congressional Black Cauc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AP</td>\n",
       "      <td>2020-03-13T04:24:56Z</td>\n",
       "      <td>https://apnews.com/9d7d4614b0a33fb63e68ecb666b...</td>\n",
       "      <td>Florida could be knockout punch for Sanders’ 2...</td>\n",
       "      <td>MIAMI (AP) — Florida has never been known as a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publisher                  date  \\\n",
       "0        AP  2020-03-13T12:37:22Z   \n",
       "1        AP  2020-03-13T15:22:24Z   \n",
       "2        AP  2020-03-13T13:13:09Z   \n",
       "3        AP  2020-03-13T12:00:17Z   \n",
       "4        AP  2020-03-13T04:24:56Z   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://apnews.com/83b0c8e168548fd453b0c177dd1...   \n",
       "1  https://apnews.com/663e745a80358c042786d2a5624...   \n",
       "2  https://apnews.com/d7cb8610b50a2e79ce1a72929f2...   \n",
       "3  https://apnews.com/0c26235718a02157e5831933f57...   \n",
       "4  https://apnews.com/9d7d4614b0a33fb63e68ecb666b...   \n",
       "\n",
       "                                       article_title  \\\n",
       "0  Pelosi, White House near agreement on coronavi...   \n",
       "1  Trump to hold news conference as he seeks to c...   \n",
       "2  Trump administration: $1.3M for fast virus tes...   \n",
       "3  Chairwoman of Congressional Black Caucus endor...   \n",
       "4  Florida could be knockout punch for Sanders’ 2...   \n",
       "\n",
       "                                        article_text  \n",
       "0  WASHINGTON (AP) — House Speaker Nancy Pelosi a...  \n",
       "1  WASHINGTON (AP) — President Donald Trump will ...  \n",
       "2  President Donald Trump’s administration announ...  \n",
       "3  The chairwoman of the Congressional Black Cauc...  \n",
       "4  MIAMI (AP) — Florida has never been known as a...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join ap data\n",
    "ap_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'AP',\n",
    "    'date': ap_dates,\n",
    "    'link': ap_links,\n",
    "    'article_title': ap_titles,\n",
    "    'article_text': ap_text \n",
    "})\n",
    "\n",
    "ap_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in old data\n",
    "old_ap_data = pd.read_csv('data/ap_data.csv')\n",
    "num_old = len(old_ap_data)\n",
    "\n",
    "# append new data\n",
    "ap_data = old_ap_data.append(ap_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "ap_data.to_csv(\"data/ap_data.csv\", index = False)\n",
    "num_now = len(ap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entries in old data: 115\n",
      "total number of entries in new data: 135\n",
      "difference: 20\n"
     ]
    }
   ],
   "source": [
    "# see number of articles\n",
    "print(\"number of entries in old data: {}\".format(num_old))\n",
    "print(\"total number of entries in new data: {}\".format(num_now))\n",
    "print(\"difference: {}\".format(num_now-num_old))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. New York Times - Liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "nyt_request = requests.get('https://www.nytimes.com/section/politics')\n",
    "nyt_homepage = nyt_request.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup \n",
    "nyt_soup = BeautifulSoup(nyt_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homepage URLs\n",
    "nyt_tags_home = nyt_soup.find_all('h2', class_=\"css-l2vidh e4e4i5l1\")\n",
    "\n",
    "# archive URLs\n",
    "nyt_tags_archive = nyt_soup.find_all('div', class_='css-1l4spti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup \n",
    "nyt_links = []\n",
    "nyt_titles = []\n",
    "nyt_dates = []\n",
    "nyt_contents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homepage articles\n",
    "for n in np.arange(0, len(nyt_tags_home)):\n",
    "\n",
    "    # get article link\n",
    "    link = nyt_tags_home[n].find('a')['href']\n",
    "    link = \"https://www.nytimes.com\" + link\n",
    "    nyt_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = nyt_tags_home[n].find('a').get_text()\n",
    "    nyt_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.time.attrs['datetime']\n",
    "    date = date[:-15]\n",
    "    nyt_dates.append(date)\n",
    "    \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', {'class':['css-53u6y8', 'css-1fanzo5']})\n",
    "    final_article = \" \".join([item.text for item in body])\n",
    "        \n",
    "    nyt_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# archive articles\n",
    "for n in np.arange(0, len(nyt_tags_archive)):\n",
    "\n",
    "    # get article link\n",
    "    link = nyt_tags_archive[n].find('a')['href']\n",
    "    link = \"https://www.nytimes.com\" + link\n",
    "    nyt_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = nyt_tags_archive[n].find('a').get_text()\n",
    "    nyt_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.time.attrs['datetime']\n",
    "    date = date[:-15]\n",
    "    nyt_dates.append(date)\n",
    "        \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', attrs = {'class':['css-53u6y8', 'css-1fanzo5 StoryBodyCompanionColumn']})\n",
    "    final_article = \" \".join([item.text for item in body])\n",
    "        \n",
    "    nyt_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembling data\n",
    "nyt_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'new_york_times',\n",
    "    'date': nyt_dates,\n",
    "    'link': nyt_links,\n",
    "    'article_title': nyt_titles,\n",
    "    'article_text': nyt_contents \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>new_york_times</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>https://www.nytimes.com/2020/03/12/business/ec...</td>\n",
       "      <td>Congress Nears Stimulus Deal With White House ...</td>\n",
       "      <td>WASHINGTON — Financial markets plunged on Thur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>new_york_times</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>https://www.nytimes.com/2020/03/12/us/politics...</td>\n",
       "      <td>The President as Bystander: Trump Struggles to...</td>\n",
       "      <td>WASHINGTON — As he confronts the most serious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>new_york_times</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>https://www.nytimes.com/2020/03/13/us/politics...</td>\n",
       "      <td>How 4 Big States Are Preparing to Vote as the ...</td>\n",
       "      <td>Elections officials in the next four Democrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>new_york_times</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>https://www.nytimes.com/2020/03/13/us/politics...</td>\n",
       "      <td>Afraid of Coronavirus? That Might Say Somethin...</td>\n",
       "      <td>Welcome to Poll Watch, our weekly look at poll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>new_york_times</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>https://www.nytimes.com/2020/03/13/us/politics...</td>\n",
       "      <td>Trump Administration Moves to Speed Coronaviru...</td>\n",
       "      <td>WASHINGTON — The Trump administration moved on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        publisher        date  \\\n",
       "0  new_york_times  2020-03-12   \n",
       "1  new_york_times  2020-03-12   \n",
       "2  new_york_times  2020-03-13   \n",
       "3  new_york_times  2020-03-13   \n",
       "4  new_york_times  2020-03-13   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.nytimes.com/2020/03/12/business/ec...   \n",
       "1  https://www.nytimes.com/2020/03/12/us/politics...   \n",
       "2  https://www.nytimes.com/2020/03/13/us/politics...   \n",
       "3  https://www.nytimes.com/2020/03/13/us/politics...   \n",
       "4  https://www.nytimes.com/2020/03/13/us/politics...   \n",
       "\n",
       "                                       article_title  \\\n",
       "0  Congress Nears Stimulus Deal With White House ...   \n",
       "1  The President as Bystander: Trump Struggles to...   \n",
       "2  How 4 Big States Are Preparing to Vote as the ...   \n",
       "3  Afraid of Coronavirus? That Might Say Somethin...   \n",
       "4  Trump Administration Moves to Speed Coronaviru...   \n",
       "\n",
       "                                        article_text  \n",
       "0  WASHINGTON — Financial markets plunged on Thur...  \n",
       "1  WASHINGTON — As he confronts the most serious ...  \n",
       "2  Elections officials in the next four Democrati...  \n",
       "3  Welcome to Poll Watch, our weekly look at poll...  \n",
       "4  WASHINGTON — The Trump administration moved on...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it looks nice\n",
    "nyt_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entries in old data: 41\n",
      "total number of entries in new data: 55\n"
     ]
    }
   ],
   "source": [
    "# read in old data\n",
    "old_nyt_data = pd.read_csv('data/nyt_data.csv')\n",
    "num_old = len(old_nyt_data)\n",
    "\n",
    "# append new data\n",
    "nyt_data = old_nyt_data.append(nyt_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "nyt_data.to_csv(\"data/nyt_data.csv\", index = False)\n",
    "num_now = len(nyt_data)\n",
    "\n",
    "print(\"number of entries in old data: {}\".format(num_old))\n",
    "print(\"total number of entries in new data: {}\".format(num_now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Buzzfeed - Very Liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "buzz_request = requests.get('https://www.buzzfeednews.com/section/politics')\n",
    "buzz_homepage = buzz_request.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup \n",
    "buzz_soup = BeautifulSoup(buzz_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate article URLs\n",
    "buzz_tags = buzz_soup.find_all('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "number_of_articles = min(len(buzz_tags), 30)\n",
    "\n",
    "# get article titles, content, and links\n",
    "buzz_links = []\n",
    "buzz_titles = []\n",
    "buzz_dates = []\n",
    "buzz_contents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get article titles, content, and links\n",
    "for n in np.arange(0, number_of_articles):\n",
    "\n",
    "    # get article link\n",
    "    link = buzz_tags[n].find('a')['href']\n",
    "    buzz_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = buzz_tags[n].find('a').get_text()\n",
    "    buzz_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.find_all('div', class_=\"news-article-header__timestamps\")    \n",
    "    date = \" \".join([item.text for item in date]).replace('\\n', '')\n",
    "    buzz_dates.append(date)\n",
    "    \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', attrs={'data-module':'subbuzz-text'})\n",
    "    article = \" \".join([item.text for item in body]).replace('\\n', '')\n",
    "    final_article = re.sub(r' {[^}]*}', '', article)\n",
    "        \n",
    "    buzz_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembling data\n",
    "buzz_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'buzzfeed',\n",
    "    'date': buzz_dates,\n",
    "    'link': buzz_links,\n",
    "    'article_title': buzz_titles,\n",
    "    'article_text': buzz_contents \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>Posted on March 12, 2020, at 6:21 ...</td>\n",
       "      <td>https://www.buzzfeednews.com/article/miriameld...</td>\n",
       "      <td>Coronavirus Is The Nightmare Situation People ...</td>\n",
       "      <td>Nobody knows what to do. Is it ethical to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>Posted on March 12, 2020, at 6:12 ...</td>\n",
       "      <td>https://www.buzzfeednews.com/article/mollyhens...</td>\n",
       "      <td>Katie Porter Got The CDC Director To Promise F...</td>\n",
       "      <td>California Rep. Katie Porter exacted a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>Posted on March 12, 2020, at 5:00 ...</td>\n",
       "      <td>https://www.buzzfeednews.com/article/ryancbroo...</td>\n",
       "      <td>Bernie Sanders Pitched Medicare For All As The...</td>\n",
       "      <td>Bernie Sanders turned a press statement o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>Posted on March 12, 2020, at 4:46 ...</td>\n",
       "      <td>https://www.buzzfeednews.com/article/paulmcleo...</td>\n",
       "      <td>The Trump Administration Will Move Ahead With ...</td>\n",
       "      <td>WASHINGTON — The Trump administration is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>Posted on March 12, 2020, at 2:51 ...</td>\n",
       "      <td>https://www.buzzfeednews.com/article/kadiagoba...</td>\n",
       "      <td>Members Of Congress Are Furious At The Lack Of...</td>\n",
       "      <td>WASHINGTON — A day after the World Health...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publisher                                               date  \\\n",
       "0  buzzfeed              Posted on March 12, 2020, at 6:21 ...   \n",
       "1  buzzfeed              Posted on March 12, 2020, at 6:12 ...   \n",
       "2  buzzfeed              Posted on March 12, 2020, at 5:00 ...   \n",
       "3  buzzfeed              Posted on March 12, 2020, at 4:46 ...   \n",
       "4  buzzfeed              Posted on March 12, 2020, at 2:51 ...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.buzzfeednews.com/article/miriameld...   \n",
       "1  https://www.buzzfeednews.com/article/mollyhens...   \n",
       "2  https://www.buzzfeednews.com/article/ryancbroo...   \n",
       "3  https://www.buzzfeednews.com/article/paulmcleo...   \n",
       "4  https://www.buzzfeednews.com/article/kadiagoba...   \n",
       "\n",
       "                                       article_title  \\\n",
       "0  Coronavirus Is The Nightmare Situation People ...   \n",
       "1  Katie Porter Got The CDC Director To Promise F...   \n",
       "2  Bernie Sanders Pitched Medicare For All As The...   \n",
       "3  The Trump Administration Will Move Ahead With ...   \n",
       "4  Members Of Congress Are Furious At The Lack Of...   \n",
       "\n",
       "                                        article_text  \n",
       "0       Nobody knows what to do. Is it ethical to...  \n",
       "1       California Rep. Katie Porter exacted a co...  \n",
       "2       Bernie Sanders turned a press statement o...  \n",
       "3       WASHINGTON — The Trump administration is ...  \n",
       "4       WASHINGTON — A day after the World Health...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buzz_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of entries in new data: 54\n"
     ]
    }
   ],
   "source": [
    "# read in old data\n",
    "old_buzz_data = pd.read_csv('data/buzzfeed_data.csv')\n",
    "num_old = len(old_buzz_data)\n",
    "\n",
    "# append new data\n",
    "buzz_data = old_buzz_data.append(buzz_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "buzz_data.to_csv(\"data/buzzfeed_data.csv\", index = False)\n",
    "num_now = len(buzz_data)\n",
    "\n",
    "#print(\"number of entries in old data: {}\".format(num_old))\n",
    "print(\"total number of entries in new data: {}\".format(num_now))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
