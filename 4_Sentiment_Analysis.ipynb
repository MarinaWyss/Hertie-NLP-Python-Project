{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This class pre-processes the data, runs a TextBlob sentiment analysis and creates the plots that are used on an ongoing basis. Many more plots and descriptives can be found in preparatory_scripts/all-descriptives.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis:\n",
    "    \"\"\"\n",
    "    A class to runs a TextBlob sentiment analysis and create descriptive plots.\n",
    "    \"\"\"\n",
    "    def sentence_data():\n",
    "        \"\"\"\n",
    "        Reads in sentence data from scraper.\n",
    "        return: pd.DataFrame\n",
    "        \"\"\"\n",
    "        data = pd.read_csv('data/sentence_data.csv')\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def prep_data():\n",
    "        \"\"\"\n",
    "        Removes punctuation, numbers, stopwords and lowercases from sentence data and adds to new column in data.\n",
    "        return: pd.DataFrame\n",
    "        \"\"\"\n",
    "        # setup\n",
    "        sentences = data['article_text']\n",
    "\n",
    "        # lowercase everything\n",
    "        sentences = [sentences.lower() for sentences in sentences]\n",
    "\n",
    "        # remove punctuation\n",
    "        sentences = [s.replace(\"â€™s\",'') for s in sentences] # remove apostrophe s first\n",
    "        sentences = [re.sub(r'[^\\w\\s]','',s) for s in sentences]\n",
    "\n",
    "        # remove numbers\n",
    "        sentences = [re.sub('[0-9]','', s) for s in sentences]\n",
    "\n",
    "        # remove double space\n",
    "        sentences = [s.replace(\"  \",' ') for s in sentences]\n",
    "\n",
    "        # remove stopwords\n",
    "        clean = []\n",
    "        for item in sentences:\n",
    "            for word in stopwords.words('english'):\n",
    "                item = item.replace(\" \" + word + \" \", ' ')\n",
    "            clean.append(item)\n",
    "\n",
    "        data['article_text_clean'] = clean\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def sentiment_analysis():\n",
    "        \"\"\"\n",
    "        Uses TextBlob's rule-based API to conduct sentiment analysis. Adds score to new column in data.\n",
    "        return: pd.DataFrame\n",
    "        \"\"\"\n",
    "        # setup\n",
    "        text = data['article_text_clean']\n",
    "        score = []\n",
    "        \n",
    "        for sentence in text:\n",
    "            sentence = TextBlob(sentence)\n",
    "            x = sentence.sentiment\n",
    "            x = sentence.sentiment.polarity\n",
    "            score.append(x)\n",
    "\n",
    "        data['score'] = score\n",
    "\n",
    "        # Convert float score to category based on binning to get 5 levels\n",
    "        data['sentiment'] = pd.cut(data['score'],\n",
    "                            bins=5,\n",
    "                            labels=[1, 2, 3, 4, 5])\n",
    "        data['sentiment'] = pd.to_numeric(data['sentiment'])\n",
    "        data = data.drop('score', axis=1)\n",
    "\n",
    "    def outlet_sentiment():\n",
    "        \"\"\"\n",
    "        Calculates the sentiment score breakdown as a percent per outlet.\n",
    "        return: list, dictionary\n",
    "        \"\"\"\n",
    "        # AP sentiment\n",
    "        AP = data.loc[data['publisher'] == \"AP\"]\n",
    "        AP_sent = AP['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        AP_sent_count = AP_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        AP_1 = AP_sent_count[1]/len(AP_sent)\n",
    "        AP_2 = AP_sent_count[2]/len(AP_sent)\n",
    "        AP_3 = AP_sent_count[3]/len(AP_sent)\n",
    "        AP_4 = AP_sent_count[4]/len(AP_sent)\n",
    "        AP_5 = AP_sent_count[5]/len(AP_sent)\n",
    "\n",
    "        # Breitbart sentiment\n",
    "        Breitbart = data.loc[data['publisher'] == \"Breitbart\"]\n",
    "        Breitbart_sent = Breitbart['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        Breitbart_sent_count = Breitbart_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        Breitbart_1 = Breitbart_sent_count[1]/len(Breitbart_sent)\n",
    "        Breitbart_2 = Breitbart_sent_count[2]/len(Breitbart_sent)\n",
    "        Breitbart_3 = Breitbart_sent_count[3]/len(Breitbart_sent)\n",
    "        Breitbart_4 = Breitbart_sent_count[4]/len(Breitbart_sent)\n",
    "        Breitbart_5 = Breitbart_sent_count[5]/len(Breitbart_sent)\n",
    "\n",
    "        # Fox sentiment\n",
    "        Fox = data.loc[data['publisher'] == \"Fox\"]\n",
    "        Fox_sent = Fox['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        Fox_sent_count = Fox_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        Fox_1 = Fox_sent_count[1]/len(Fox_sent)\n",
    "        Fox_2 = Fox_sent_count[2]/len(Fox_sent)\n",
    "        Fox_3 = Fox_sent_count[3]/len(Fox_sent)\n",
    "        Fox_4 = Fox_sent_count[4]/len(Fox_sent)\n",
    "        Fox_5 = Fox_sent_count[5]/len(Fox_sent)\n",
    "\n",
    "        # Buzzfeed sentiment\n",
    "        buzzfeed = data.loc[data['publisher'] == \"buzzfeed\"]\n",
    "        buzzfeed_sent = buzzfeed['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        buzzfeed_sent_count = buzzfeed_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        buzzfeed_1 = buzzfeed_sent_count[1]/len(buzzfeed_sent)\n",
    "        buzzfeed_2 = buzzfeed_sent_count[2]/len(buzzfeed_sent)\n",
    "        buzzfeed_3 = buzzfeed_sent_count[3]/len(buzzfeed_sent)\n",
    "        buzzfeed_4 = buzzfeed_sent_count[4]/len(buzzfeed_sent)\n",
    "        buzzfeed_5 = buzzfeed_sent_count[5]/len(buzzfeed_sent)\n",
    "\n",
    "        # NBC\n",
    "        nbc = data.loc[data['publisher'] == \"nbc\"]\n",
    "        nbc_sent = nbc['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        nbc_sent_count = nbc_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        nbc_1 = nbc_sent_count[1]/len(nbc_sent)\n",
    "        nbc_2 = nbc_sent_count[2]/len(nbc_sent)\n",
    "        nbc_3 = nbc_sent_count[3]/len(nbc_sent)\n",
    "        nbc_4 = nbc_sent_count[4]/len(nbc_sent)\n",
    "        nbc_5 = nbc_sent_count[5]/len(nbc_sent)\n",
    "\n",
    "        # New York Times\n",
    "        new_york_times = data.loc[data['publisher'] == \"new_york_times\"]\n",
    "        new_york_times_sent = new_york_times['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        new_york_times_sent_count = new_york_times_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        new_york_times_1 = new_york_times_sent_count[1]/len(new_york_times_sent)\n",
    "        new_york_times_2 = new_york_times_sent_count[2]/len(new_york_times_sent)\n",
    "        new_york_times_3 = new_york_times_sent_count[3]/len(new_york_times_sent)\n",
    "        new_york_times_4 = new_york_times_sent_count[4]/len(new_york_times_sent)\n",
    "        new_york_times_5 = new_york_times_sent_count[5]/len(new_york_times_sent)\n",
    "\n",
    "        # Politico\n",
    "        politico = data.loc[data['publisher'] == \"politico\"]\n",
    "        politico_sent = politico['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        politico_sent_count = politico_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        politico_1 = politico_sent_count[1]/len(politico_sent)\n",
    "        politico_2 = politico_sent_count[2]/len(politico_sent)\n",
    "        politico_3 = politico_sent_count[3]/len(politico_sent)\n",
    "        politico_4 = politico_sent_count[4]/len(politico_sent)\n",
    "        politico_5 = politico_sent_count[5]/len(politico_sent)\n",
    "\n",
    "        # Washington Times\n",
    "        washington_times = data.loc[data['publisher'] == \"washington_times\"]\n",
    "        washington_times_sent = washington_times['sentiment'].sort_values(ascending=True)\n",
    "        # get sentiment counts\n",
    "        washington_times_sent_count = washington_times_sent.value_counts().sort_index()\n",
    "        # get percent per sentiment category\n",
    "        washington_times_1 = washington_times_sent_count[1]/len(washington_times_sent)\n",
    "        washington_times_2 = washington_times_sent_count[2]/len(washington_times_sent)\n",
    "        washington_times_3 = washington_times_sent_count[3]/len(washington_times_sent)\n",
    "        washington_times_4 = washington_times_sent_count[4]/len(washington_times_sent)\n",
    "        washington_times_5 = washington_times_sent_count[5]/len(washington_times_sent)\n",
    "\n",
    "        category_names = ['Extremely negative', 'Negative','Neutral', 'Positive', 'Extremely positive']\n",
    "        publishers = {\n",
    "            'AP': [AP_1, AP_2, AP_3, AP_4, AP_5],\n",
    "            'Breitbart': [Breitbart_1, Breitbart_2, Breitbart_3, Breitbart_4, Breitbart_5],\n",
    "            'Fox': [Fox_1, Fox_2, Fox_3, Fox_4, Fox_5],\n",
    "            'Buzzfeed': [buzzfeed_1, buzzfeed_2, buzzfeed_3, buzzfeed_4, buzzfeed_5],\n",
    "            'NBC': [nbc_1, nbc_2, nbc_3, nbc_4, nbc_5],\n",
    "            'New York Times': [new_york_times_1, new_york_times_2, new_york_times_3, new_york_times_4, new_york_times_5],\n",
    "            'Politico': [politico_1, politico_2, politico_3, politico_4, politico_5],\n",
    "            'Washington Times': [washington_times_1, washington_times_2, washington_times_3, washington_times_4, washington_times_5]\n",
    "        }\n",
    "\n",
    "        return category_names, publishers\n",
    "\n",
    "    def outlet_sentiment_plot(publishers, category_names):\n",
    "        \"\"\"\n",
    "        Plots the percent count of sentiment scores per outlet. \n",
    "        return: series of subplots\n",
    "        \"\"\"\n",
    "        labels = list(publishers.keys())\n",
    "        data = np.array(list(publishers.values()))\n",
    "        data_cum = data.cumsum(axis=1)\n",
    "        category_colors = plt.get_cmap('RdYlGn')(\n",
    "            np.linspace(0.15, 0.85, data.shape[1]))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.invert_yaxis()\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.set_xlim(0, np.sum(data, axis=1).max())\n",
    "\n",
    "        for i, (colname, color) in enumerate(zip(category_names, category_colors)):\n",
    "            widths = data[:, i]\n",
    "            starts = data_cum[:, i] - widths\n",
    "            ax.barh(labels, widths, left=starts, height=0.5,\n",
    "                    label=colname, color=color)\n",
    "            xcenters = starts + widths / 2\n",
    "\n",
    "            r, g, b, _ = color\n",
    "            text_color = 'white' if r * g * b < 0.5 else 'darkgrey'\n",
    "            for y, (x, c) in enumerate(zip(xcenters, widths)):\n",
    "                ax.text(x, y, str(\"{0:.0%}\".format(c)), ha='center', va='center',\n",
    "                        color=text_color)\n",
    "        ax.legend(ncol=len(category_names), bbox_to_anchor=(0, 1),\n",
    "                  loc='lower left', fontsize='small')\n",
    "\n",
    "        return fig, ax\n",
    "\n",
    "        outlet_sentiment_plot(publishers, category_names)\n",
    "        plt.savefig('sentiment_count.png', bbox_inches='tight')\n",
    "\n",
    "    def candidate_sentiment():\n",
    "        \"\"\"\n",
    "        Calculates the sentiment averages accross all candidates, per candidate and per candidate and outlet.\n",
    "        return: a series of lists\n",
    "        \"\"\"\n",
    "        # total average\n",
    "        sent_mean = data['sentiment'].mean()\n",
    "\n",
    "        #trump\n",
    "        trump = data.loc[data['Trump'] == 1]\n",
    "        trump_sent_mean = trump['sentiment'].mean()\n",
    "        trump_sentiment = trump.groupby('publisher')['sentiment'].mean().reset_index()\n",
    "\n",
    "        #sanders\n",
    "        sanders = data.loc[data['Sanders'] == 1]\n",
    "        sanders_sent_mean = sanders['sentiment'].mean()\n",
    "        sanders_sentiment = sanders.groupby('publisher')['sentiment'].mean().reset_index()\n",
    "\n",
    "        #biden\n",
    "        biden = data.loc[data['Biden'] == 1]\n",
    "        biden_sent_mean = biden['sentiment'].mean()\n",
    "        biden_sentiment = biden.groupby('publisher')['sentiment'].mean().reset_index()\n",
    "\n",
    "        return sent_mean, trump, trump_sent_mean, trump_sentiment, sanders, sanders_sent_mean, sanders_sentiment, biden, biden_sent_mean, biden_sentiment\n",
    "\n",
    "    def candidate_sentiment_plot():\n",
    "        \"\"\"\n",
    "        Plots difference in each candidate's sentiment average to overall sentiment mean.\n",
    "        return: bar plot\n",
    "        \"\"\"\n",
    "        sentiment = [trump_sent_mean - sent_mean,\n",
    "                     sanders_sent_mean - sent_mean, \n",
    "                     biden_sent_mean - sent_mean, \n",
    "                     warren_sent_mean - sent_mean, \n",
    "                     buttigieg_sent_mean - sent_mean, \n",
    "                     bloomberg_sent_mean - sent_mean, \n",
    "                     klobuchar_sent_mean - sent_mean, \n",
    "                     yang_sent_mean - sent_mean, \n",
    "                     steyer_sent_mean - sent_mean, \n",
    "                     gabbard_sent_mean - sent_mean]\n",
    "        candidates = ('trump', 'sanders', 'biden', 'warren', 'buttigieg', 'bloomberg','klobuchar', 'yang', 'steyer', 'gabbard')\n",
    "\n",
    "        colors = [\"darkslategrey\", \"teal\", \"steelblue\", \"slategrey\", \"lightsteelblue\", \"blanchedalmond\", \"lightsalmon\", \"coral\", \"tomato\", \"firebrick\"]\n",
    "\n",
    "        plt.bar(candidates, sentiment, color=colors)\n",
    "        plt.xticks(candidates)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "        plt.text(x=-0.8, y=-.091, s=\"Average Sentiment:\" + str(sent_mean), horizontalalignment='left')\n",
    "\n",
    "    def trump_sentiment_plot():\n",
    "        \"\"\"\n",
    "        Plots difference in Trump's sentiment average per publisher to his overall sentiment mean.\n",
    "        return: bar plot\n",
    "        \"\"\"\n",
    "        sentiment = trump_sentiment['sentiment'] - trump_sent_mean\n",
    "        outlet = trump_sentiment['publisher']\n",
    "\n",
    "        plt.bar(outlet, sentiment, color = \"firebrick\") \n",
    "        plt.xticks(outlet)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.suptitle('Trump: Sentiment by Publisher', fontsize=16)\n",
    "        plt.text(x=-0.8, y=-.091, s=\"Trump's sentiment mean:\" + str(trump_sent_mean), horizontalalignment='left')\n",
    "        plt.text(x=-0.8, y=-.1, s=\"Number of Trump sentences:\" + str(len(trump)), horizontalalignment='left')\n",
    "\n",
    "        plt.savefig('trump.png', bbox_inches='tight')\n",
    "\n",
    "    def sanders_sentiment_plot():\n",
    "        \"\"\"\n",
    "        Plots difference in Sander's sentiment average per publisher to his overall sentiment mean.\n",
    "        return: bar plot\n",
    "        \"\"\"\n",
    "        sentiment = sanders_sentiment['sentiment'] - sanders_sent_mean\n",
    "        outlet = sanders_sentiment['publisher']\n",
    "\n",
    "        plt.bar(outlet, sentiment, color = \"tomato\") \n",
    "        plt.xticks(outlet)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.suptitle('Sanders: Sentiment by Publisher', fontsize=16)\n",
    "        plt.text(x=-0.8, y=-.16, s=\"Sanders's sentiment mean:\" + str(sanders_sent_mean), horizontalalignment='left')\n",
    "        plt.text(x=-0.8, y=-.17, s=\"Number of Sanders sentences:\" + str(len(sanders)), horizontalalignment='left')\n",
    "\n",
    "        plt.savefig('sanders.png', bbox_inches='tight')\n",
    "\n",
    "    def biden_sentiment_plot():\n",
    "        \"\"\"\n",
    "        Plots difference in Biden's sentiment average per publisher to his overall sentiment mean.\n",
    "        return: bar plot\n",
    "        \"\"\"\n",
    "        sentiment = biden_sentiment['sentiment'] - biden_sent_mean\n",
    "        outlet = biden_sentiment['publisher']\n",
    "\n",
    "        plt.bar(outlet, sentiment, color = \"coral\") \n",
    "        plt.xticks(outlet)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.suptitle('Biden: Sentiment by Publisher', fontsize=16)\n",
    "        plt.text(x=-0.8, y=-.13, s=\"Biden's sentiment mean:\" + str(biden_sent_mean), horizontalalignment='left')\n",
    "        plt.text(x=-0.8, y=-.14, s=\"Number of Biden sentences:\" + str(len(biden)), horizontalalignment='left')\n",
    "\n",
    "        plt.savefig('biden.png', bbox_inches='tight')\n",
    "\n",
    "    def sentiment_time():\n",
    "        \"\"\"\n",
    "        Calculates the mean sentiment score per candidate per day.\n",
    "        return: DataFrame\n",
    "        \"\"\"\n",
    "        warnings.simplefilter(action='ignore')\n",
    "        # filter sentences only about one candidate\n",
    "        candidate_sentiment = data.loc[data['candidates_mentioned'] == 1]\n",
    "\n",
    "        # create new column with candidate name\n",
    "        candidate_sentiment['candidate'] = candidate_sentiment['article_text'].str.extract('({})'.format('|'.join(candidates)),\n",
    "                                            flags = re.IGNORECASE, expand = False).str.lower().fillna('')\n",
    "        candidate_sentiment['candidate'] = np.where(candidate_sentiment['article_text'].str.contains('bernie'), 'sanders', candidate_sentiment['candidate'])\n",
    "        candidate_sentiment = candidate_sentiment[['date', 'sentiment', 'candidate']]\n",
    "\n",
    "        # make dates consistent and filter for time frame\n",
    "        candidate_sentiment['date'] = pd.to_datetime(candidate_sentiment['date'], errors='coerce')\n",
    "        mask = (candidate_sentiment['date'].astype('str') >= \"2020-03-01\") & (candidate_sentiment['date'].astype('str') < \"2020-03-30\")\n",
    "        candidate_sentiment = candidate_sentiment.loc[mask]\n",
    "\n",
    "        # mean sentiment per day\n",
    "        mean_per_day = candidate_sentiment.groupby(['date', 'candidate']).mean()\n",
    "        mean_per_day.reset_index(inplace = True)\n",
    "\n",
    "        return mean_per_day\n",
    "\n",
    "    def sentiment_time_plot():\n",
    "        \"\"\"\n",
    "        Plots sentiment scores per candidate over time\n",
    "        return: bar plot\n",
    "        \"\"\"\n",
    "        chart = sns.lineplot(x = 'date', y = 'sentiment', hue = 'candidate', data = mean_per_day)\n",
    "        plt.setp(chart.get_xticklabels(), rotation = 45)\n",
    "        plt.setp(chart.get_xticklabels(), rotation = 45)\n",
    "        plt.title('Average Sentiment Over Time')\n",
    "        plt.title('Average Sentiment Over Time')\n",
    "        chart.legend(loc='center right', bbox_to_anchor=(1.3, 0.5), ncol=1)\n",
    "        plt.savefig('sentiment_time.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
