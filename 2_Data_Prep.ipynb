{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data sets\n",
    "breitbart = pd.read_csv('data/breitbart_data.csv')\n",
    "fox = pd.read_csv('data/fox_data.csv')\n",
    "wt = pd.read_csv('data/wt_data.csv')\n",
    "ap = pd.read_csv('data/ap_data.csv')\n",
    "nbc = pd.read_csv('data/nbc_data.csv')\n",
    "nyt = pd.read_csv('data/nyt_data.csv')\n",
    "politico = pd.read_csv('data/politico_data.csv')\n",
    "buzzfeed = pd.read_csv('data/buzzfeed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make dates comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox['date'] = [x.split('T')[0] for x in fox['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt['date'] = [x.replace(' -\\n\\t\\t\\t\\n\\t\\t\\t\\tAssociated Press\\n -    Updated:', '') for x in wt['date']]\n",
    "wt['date'] = [x.replace(' -\\n\\t\\t\\t\\n\\t\\t\\t\\tThe Washington Times\\n -    Updated:', '') for x in wt['date']]\n",
    "wt['date'] = [parse(x) for x in wt['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap['date'] = [x.split('T')[0] for x in ap['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc = nbc.copy().dropna()\n",
    "nbc['date'] = [parse(x) for x in nbc['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "buzzfeed['date'] = [x.replace('Posted on ', '').replace('Last updated on ', '') for x in buzzfeed['date']]\n",
    "buzzfeed['date'] = [x.strip() for x in buzzfeed['date']]\n",
    "buzzfeed['date'] = [x.split(',')[0:2] for x in buzzfeed['date']]\n",
    "buzzfeed['date'] = [''.join(x) for x in buzzfeed['date']]\n",
    "buzzfeed['date'] = [parse(x) for x in buzzfeed['date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat([\n",
    "    breitbart,\n",
    "    fox,\n",
    "    wt,\n",
    "    ap,\n",
    "    nbc,\n",
    "    nyt,\n",
    "    politico,\n",
    "    buzzfeed\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Articles to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create article id #\n",
    "full_data = full_data.rename_axis('article_id').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split article text to sentences\n",
    "sentences = full_data['article_text'].copy().str.split('.').apply(pd.Series, 1).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add correct article id # to each sentence\n",
    "sentences.index.droplevel(-1) \n",
    "sentences.name = 'article_text'\n",
    "sentences = sentences.reset_index().drop(columns = 'level_1').rename(columns = {'level_0': 'article_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data set without original paragraph-form article text\n",
    "sentence_data = full_data.copy()\n",
    "del sentence_data['article_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge sentence article text\n",
    "sentence_data = sentence_data.merge(sentences, how='left', on='article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "final_sentence_data = sentence_data.copy()\n",
    "mask = final_sentence_data['article_text'].astype(str).str.len() < 15\n",
    "final_sentence_data.loc[mask, 'article_text'] = ''\n",
    "final_sentence_data = final_sentence_data[(final_sentence_data['article_text'] != '')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
