{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper Tool for 5 US Media Outlets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Breitbart - Very Conservative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get links from the Breitbart homepage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fox - Conservative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get links from the Fox Politics homepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.foxnews.com/category/politics/2020-presidential-election <- 127 links // 15  without junk\n",
    "# https://www.foxnews.com/politics <- 150 links (but junk?) // 31 without junk\n",
    "# i also tried running this for each candidate's section but there is overlap in articles\n",
    "\n",
    "# load the HTML content using requests and save into a variable\n",
    "r3 = requests.get('https://www.foxnews.com/politics')\n",
    "homepage3 = r3.content\n",
    "\n",
    "# create a soup to allow BeautifulSoup to work\n",
    "soup3 = BeautifulSoup(homepage3, 'html.parser')\n",
    "\n",
    "# locate and retrieve all links - WAS NOT ABLE TO ISOLATE JUST ARTICLE LINKS BECUASE NO UNIQUE TAG ELEMENT!!\n",
    "# you can see how complex the homepage is: print(soup3.prettify())\n",
    "homepage_tags3 = soup3.find_all('a')\n",
    "homepage_links3 = []\n",
    "\n",
    "for link in homepage_tags3:\n",
    "    homepage_links3.append(link.get('href'))\n",
    "\n",
    "# remove duplicates by turning list into a set\n",
    "homepage_links3 = set(homepage_links3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove junk links from list <- MAYBE THIS COULD BE DONE IN A BETTER WAY??\n",
    "# creating a list of exact junk links that will never be needed when pulling from the homepage\n",
    "junk_links3 = ['/', '/us', '/world', '/opinion', '/politics', '/entertainment', '//www.foxbusiness.com', \n",
    "                  '/lifestyle', '/shows', '//www.foxnews.com/shows/fox-nation', '//radio.foxnews.com/podcast',\n",
    "                  '#', '//foxnews.com/weather/your-weather/index.html', '#', '#', \n",
    "                  '//video.foxnews.com/v/5614615980001/?#sp=watch-live', '#', '/us', '/world', '/opinion', '/politics', \n",
    "                  '/official-polls', '/category/politics/elections', \n",
    "                  '/entertainment', '//video.foxnews.com/playlist/entertainment-latest-entertainment/', \n",
    "                  '//www.foxbusiness.com/', '//www.foxbusiness.com/markets', '//www.foxbusiness.com/politics', \n",
    "                  '//www.foxbusiness.com/category/technology', '//www.foxbusiness.com/features', \n",
    "                  '//www.foxbusiness.com/category/business-leaders', '/lifestyle', '/food-drink', '/auto', \n",
    "                  '/travel', '/family', '/science', '/tech', '/health', '/shows', '/shows', \n",
    "                  '/person/personalities', '//video.foxnews.com/v/5614615980001/?#sp=watch-live', \n",
    "                  '//video.foxnews.com/playlist/episodic-most-recent-episodes/', \n",
    "                  '//video.foxnews.com/#sp=show-clips', '//video.foxnews.com/#sp=news-clips', \n",
    "                  '//www.foxnews.com/contact', '//foxcareers.com/Search/SearchResults?brand=Fox%20News%20Careers', \n",
    "                  '/foxaroundtheworld/', 'mailto:adsales@foxnews.com?subject=Advertising%20Inquiry', \n",
    "                  '//press.foxnews.com/media-contacts/', '//press.foxnews.com/', '/compliance', \n",
    "                  'https://supplierdiversity.foxnews.com/', '//www.foxnews.com/shows/fox-nation', '//shop.foxnews.com', \n",
    "                  '/go', '//radio.foxnews.com/', '/alerts/subscribe', '/newsletter-signup/alerts', '//radio.foxnews.com/podcast', \n",
    "                  '/apps-products', '//www.foxnews.com', '/terms-of-use', '/privacy-policy', '/donotsell', '/closed-captioning', \n",
    "                  '//help.foxnews.com', '/contact', '//www.facebook.com/FoxNews', '//twitter.com/foxnews', '//www.google.com/+FoxNews', \n",
    "                  '//www.instagram.com/foxnews', '/about/rss/', '/alerts/subscribe', 'https://flipboard.com/@FoxNews', \n",
    "                  '//www.foxnews.com/rss/index.html', '//www.foxnews.com/alerts/subscribe.html', \n",
    "                   '/accessibility-statement', 'https://video.foxnews.com/v/' ]\n",
    "\n",
    "# removing all links that lead to section pages AND other specified junk URLs\n",
    "homepage_links3 = [x for x in homepage_links3 if \"/category\" not in x] \n",
    "homepage_links3 = [x for x in homepage_links3 if \"/v/\" not in x] \n",
    "homepage_links3 = [x for x in homepage_links3 if x not in junk_links3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add https://www.foxnews.com to links that don't have this\n",
    "# create new list for prepared links\n",
    "hp_links3 = []\n",
    "\n",
    "for item in homepage_links3:\n",
    "    new_item = 'https://www.foxnews.com' + item\n",
    "    hp_links3.append(new_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: check for duplicates to set of existing URLs to make sure we only pull data for new ones\n",
    "    # import full dataset in\n",
    "    # remove urls in homepage_links3 that are already included in the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get article text and other relevent data from new articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas dataframe where all of the retrieved data will be stored\n",
    "article_data3 = pd.DataFrame()\n",
    "\n",
    "article_data3[headline] = []\n",
    "article_data3[date_published] = []\n",
    "article_data3[date_modified] = []\n",
    "article_data3[description] = []\n",
    "article_data3[author] = []\n",
    "article_data3[url] = []\n",
    "\n",
    "#export empty df to file\n",
    "article_data3.to_csv('Fox_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\\n        \"headline\": \"Mike Bloomberg suspends...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\\n        \"datePublished\": \"2020-03-04T10:15:0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\n        \"dateModified\": \"2020-03-04T11:35:06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\\n        \"description\": \"Former New York City...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\\n          \"name\": \"Paul Steinhauser\"\\n        }</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  \\n        \"headline\": \"Mike Bloomberg suspends...\n",
       "1  \\n        \"datePublished\": \"2020-03-04T10:15:0...\n",
       "2  \\n        \"dateModified\": \"2020-03-04T11:35:06...\n",
       "3  \\n        \"description\": \"Former New York City...\n",
       "4  \\n          \"name\": \"Paul Steinhauser\"\\n        }"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing with a real URL\n",
    "# load the HTML content using requests and save into a variable\n",
    "r3_article = requests.get('https://www.foxnews.com/politics/mike-bloomberg-suspends-presidential-campaign-after-super-tuesday-show')\n",
    "article3 = r3_article.content\n",
    "\n",
    "# create a soups to allow BeautifulSoup to work\n",
    "article_soup3 = BeautifulSoup(article3, 'html.parser')\n",
    "\n",
    "# retrieve article specific metadata\n",
    "metadata3 = article_soup3.find_all(\"script\")[2].get_text()\n",
    "metadata3 = metadata3.split(\",\")\n",
    "\n",
    "article_data3 = []\n",
    "\n",
    "headline = []\n",
    "date_published = []\n",
    "date_modified = []\n",
    "description = []\n",
    "author = []\n",
    "url = []\n",
    "\n",
    "\n",
    "for item in metadata3:\n",
    "    if 'headline' in item:\n",
    "        headline.append(item)\n",
    "    elif 'datePublished' in item:\n",
    "        date_published.append(item)\n",
    "    elif 'dateModified' in item:\n",
    "        date_modified.append(item)\n",
    "    elif 'description' in item:\n",
    "        description.append(item)\n",
    "    elif 'name' in item and 'Fox News' not in item:\n",
    "        author.append(item)\n",
    "    elif 'mainEntityOfPage' in item:\n",
    "        url.append(item)\n",
    "        \n",
    "article_data3.append(headline)\n",
    "article_data3.append(date_published)\n",
    "article_data3.append(date_modified)\n",
    "article_data3.append(description)\n",
    "article_data3.append(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collection of all responses\n",
    "all_responses = pd.read_csv(\"Fox_Data.csv\", index_col=[0])\n",
    "\n",
    "# merge new increment of data to the csv\n",
    "all_responses = all_responses.append(response_df, ignore_index=True)\n",
    "\n",
    "#export with new increment to save\n",
    "all_responses.to_csv('Fox_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve article text\n",
    "article_text3 = article_soup3.find_all(\"script\")[2].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<meta content=\"Dana Blanton\" data-hid=\"dc.creator\" data-n-head=\"true\" name=\"dc.creator\" scheme=\"dcterms.creator\"/>\n"
     ]
    }
   ],
   "source": [
    "# another spot the author is located just in case\n",
    "# yay = article_soup3.find_all(\"meta\")[17]\n",
    "#print(yay)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
