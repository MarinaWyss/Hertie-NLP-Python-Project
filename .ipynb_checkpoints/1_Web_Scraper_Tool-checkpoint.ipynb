{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper Tool for 5 US Media Outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import UnicodeDammit\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Breitbart - Very Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "breitbart_request = requests.get('https://www.breitbart.com/politics/')\n",
    "breitbart_homepage = breitbart_request.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup \n",
    "breitbart_soup = BeautifulSoup(breitbart_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# locate article URLs\n",
    "breitbart_tags = breitbart_soup.find_all('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "number_of_articles = min(len(breitbart_tags), 30)\n",
    "\n",
    "breitbart_links = []\n",
    "breitbart_titles = []\n",
    "breitbart_dates = []\n",
    "breitbart_contents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get article titles, content, and links\n",
    "for n in np.arange(0, number_of_articles):\n",
    "\n",
    "    # get article link\n",
    "    link = breitbart_tags[n].find('a')['href']\n",
    "    link = \"https://www.breitbart.com\" + link\n",
    "    breitbart_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = breitbart_tags[n].find('a').get_text()\n",
    "    breitbart_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.time.attrs['datetime']\n",
    "    date = date[:-10]\n",
    "    breitbart_dates.append(date)\n",
    "    \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', class_='entry-content')\n",
    "    x = body[0].find_all('p')\n",
    "    \n",
    "    # combine paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        list_paragraphs.append(paragraph)\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "        \n",
    "    breitbart_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembling data\n",
    "breitbart_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'Breitbart',\n",
    "    'date': breitbart_dates,\n",
    "    'link': breitbart_links,\n",
    "    'article_title': breitbart_titles,\n",
    "    'article_text': breitbart_contents \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A report from the Swedish Defence Research Ins...</td>\n",
       "      <td>Report: Sweden May Be Most ‘Incel’ Country in ...</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>https://www.breitbart.com/europe/2020/03/08/re...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The American Conservative Union (ACU) announce...</td>\n",
       "      <td>ACU: CPAC Attendee Tested Positive for Coronav...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/politics/2020/03/07/...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Former Illinois Gov. Rod Blagojevich ripped in...</td>\n",
       "      <td>Exclusive — Rod Blagojevich Explains Why He Is...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/politics/2020/03/07/...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politico continued the media’s effort to trash...</td>\n",
       "      <td>Pollak: Politico Continues Media’s Quest to Bl...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/the-media/2020/03/07...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On Friday’s “PBS NewsHour,” columnist Mark Shi...</td>\n",
       "      <td>Shields: Nobody Understands ‘What a Biden Pres...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.breitbart.com/clips/2020/03/07/shi...</td>\n",
       "      <td>Breitbart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_text  \\\n",
       "0  A report from the Swedish Defence Research Ins...   \n",
       "1  The American Conservative Union (ACU) announce...   \n",
       "2  Former Illinois Gov. Rod Blagojevich ripped in...   \n",
       "3  Politico continued the media’s effort to trash...   \n",
       "4  On Friday’s “PBS NewsHour,” columnist Mark Shi...   \n",
       "\n",
       "                                       article_title        date  \\\n",
       "0  Report: Sweden May Be Most ‘Incel’ Country in ...  2020-03-08   \n",
       "1  ACU: CPAC Attendee Tested Positive for Coronav...  2020-03-07   \n",
       "2  Exclusive — Rod Blagojevich Explains Why He Is...  2020-03-07   \n",
       "3  Pollak: Politico Continues Media’s Quest to Bl...  2020-03-07   \n",
       "4  Shields: Nobody Understands ‘What a Biden Pres...  2020-03-07   \n",
       "\n",
       "                                                link  publisher  \n",
       "0  https://www.breitbart.com/europe/2020/03/08/re...  Breitbart  \n",
       "1  https://www.breitbart.com/politics/2020/03/07/...  Breitbart  \n",
       "2  https://www.breitbart.com/politics/2020/03/07/...  Breitbart  \n",
       "3  https://www.breitbart.com/the-media/2020/03/07...  Breitbart  \n",
       "4  https://www.breitbart.com/clips/2020/03/07/shi...  Breitbart  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it looks nice\n",
    "breitbart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entries in old data: 14\n",
      "total number of entries in new data: 30\n"
     ]
    }
   ],
   "source": [
    "# read in old data\n",
    "old_breitbart_data = pd.read_csv('data/breitbart_data.csv')\n",
    "num_old = len(old_breitbart_data)\n",
    "\n",
    "# append new data\n",
    "breitbart_data = old_breitbart_data.append(breitbart_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "breitbart_data.to_csv(\"data/breitbart_data.csv\", index = False)\n",
    "num_now = len(breitbart_data)\n",
    "\n",
    "print(\"number of entries in old data: {}\".format(num_old))\n",
    "print(\"total number of entries in new data: {}\".format(num_now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fox - Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "fox_requests = requests.get('https://www.foxnews.com/politics')\n",
    "fox_homepage = fox_requests.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a soup to allow BeautifulSoup to work\n",
    "fox_soup = BeautifulSoup(fox_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate article links\n",
    "fox_tags = fox_soup.find_all('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "fox_links = []\n",
    "fox_text = []\n",
    "fox_titles = []\n",
    "fox_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_articles = 30\n",
    "\n",
    "# get homepage article links\n",
    "for n in np.arange(0, number_of_articles):\n",
    "    link = fox_tags[n].find('a')\n",
    "    link = link.get('href')\n",
    "    link = \"https://foxnews.com\" + link\n",
    "    fox_links.append(link)\n",
    "    fox_links = [x for x in fox_links if \"/v/\" not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep for article content\n",
    "for link in fox_links:\n",
    "    fox_article_request = requests.get(link)\n",
    "    fox_article = fox_article_request.content\n",
    "    fox_article_soup = BeautifulSoup(fox_article, 'html.parser')\n",
    "    \n",
    "    # get article metadata\n",
    "    fox_metadata = fox_article_soup.find_all('script')[2].get_text()\n",
    "    fox_metadata = fox_metadata.split(\",\")\n",
    "    \n",
    "    for item in fox_metadata:\n",
    "\n",
    "        # get article title\n",
    "        if 'headline' in item:\n",
    "            item = item.replace('\\n',\"\")\n",
    "            item = item.replace('headline', \"\")\n",
    "            item = item.replace(':', \"\")\n",
    "            item = item.replace('\"', '')\n",
    "            fox_titles.append(item)\n",
    "        \n",
    "        # get article date\n",
    "        elif 'datePublished' in item:\n",
    "            item = item.replace('\\n',\"\")\n",
    "            item = item.replace('datePublished', \"\")\n",
    "            item = item.replace(':', \"\")\n",
    "            item = item.replace('\"', '')\n",
    "            fox_dates.append(item)\n",
    "    \n",
    "    # get article text\n",
    "    body = fox_article_soup.find_all('div')\n",
    "    x = body[0].find_all('p')\n",
    "    \n",
    "    # combine paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        paragraph = paragraph.replace('\\n',\"\")\n",
    "        list_paragraphs.append(paragraph)\n",
    "        \n",
    "        # removing copyright info and newsletter junk from the article\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "        final_article = final_article.replace(\"This material may not be published, broadcast, rewritten, or redistributed. ©2020 FOX News Network, LLC. All rights reserved. All market data delayed 20 minutes.\", \" \")\n",
    "        final_article = final_article.replace(\"This material may not be published, broadcast, rewritten,\", \" \")\n",
    "        final_article = final_article.replace(\"or redistributed. ©2020 FOX News Network, LLC. All rights reserved.\", \" \")\n",
    "        final_article = final_article.replace(\"All market data delayed 20 minutes.\", \" \")\n",
    "        final_article = final_article.replace(\"Get all the stories you need-to-know from the most powerful name in news delivered first thing every morning to your inbox Subscribed You've successfully subscribed to this newsletter!\", \" \")\n",
    "    fox_text.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-09T162213-0400</td>\n",
       "      <td>https://foxnews.com/politics/bernie-sanders-fo...</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Democratic president...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-09T155153-0400</td>\n",
       "      <td>https://foxnews.com/politics/gop-rep-doug-coro...</td>\n",
       "      <td>Two GOP reps self-quarantine after co...</td>\n",
       "      <td>'Dr. Oz Show' host D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-09T190439-0400</td>\n",
       "      <td>https://foxnews.com/politics/trump-congress-pa...</td>\n",
       "      <td>Trump to pitch Congress on payroll ta...</td>\n",
       "      <td>Dr. Mehmet Oz descri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-10T044655-0400</td>\n",
       "      <td>https://foxnews.com/politics/us-begins-withdra...</td>\n",
       "      <td>US begins withdrawing troops from Afg...</td>\n",
       "      <td>The United States b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2020-03-09T231941-0400</td>\n",
       "      <td>https://foxnews.com/politics/sanders-fights-fo...</td>\n",
       "      <td>Sanders fights for another rust belt ...</td>\n",
       "      <td>Democratic president...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publisher                             date  \\\n",
       "0       Fox           2020-03-09T162213-0400   \n",
       "1       Fox           2020-03-09T155153-0400   \n",
       "2       Fox           2020-03-09T190439-0400   \n",
       "3       Fox           2020-03-10T044655-0400   \n",
       "4       Fox           2020-03-09T231941-0400   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://foxnews.com/politics/bernie-sanders-fo...   \n",
       "1  https://foxnews.com/politics/gop-rep-doug-coro...   \n",
       "2  https://foxnews.com/politics/trump-congress-pa...   \n",
       "3  https://foxnews.com/politics/us-begins-withdra...   \n",
       "4  https://foxnews.com/politics/sanders-fights-fo...   \n",
       "\n",
       "                                       article_title  \\\n",
       "0                                     Bernie Sanders   \n",
       "1           Two GOP reps self-quarantine after co...   \n",
       "2           Trump to pitch Congress on payroll ta...   \n",
       "3           US begins withdrawing troops from Afg...   \n",
       "4           Sanders fights for another rust belt ...   \n",
       "\n",
       "                                        article_text  \n",
       "0                            Democratic president...  \n",
       "1                            'Dr. Oz Show' host D...  \n",
       "2                            Dr. Mehmet Oz descri...  \n",
       "3                             The United States b...  \n",
       "4                            Democratic president...  "
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join fox data\n",
    "fox_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'Fox',\n",
    "    'date': fox_dates,\n",
    "    'link': fox_links,\n",
    "    'article_title': fox_titles,\n",
    "    'article_text': fox_text \n",
    "})\n",
    "\n",
    "fox_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in old data\n",
    "old_fox_data = pd.read_csv('data/fox_data.csv')\n",
    "\n",
    "# append new data\n",
    "fox_data = old_fox_data.append(fox_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "fox_data.to_csv(\"data/fox_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "# see number of articles\n",
    "print(len(fox_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Associated Press - Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "ap_requests = requests.get('https://apnews.com/apf-politics')\n",
    "ap_homepage = ap_requests.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a soup to allow BeautifulSoup to work\n",
    "ap_soup = BeautifulSoup(ap_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate articles\n",
    "ap_tags = ap_soup.find_all('a', class_=\"Component-headline-0-2-105\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "number_of_articles = min(len(ap_tags), 30)\n",
    "\n",
    "ap_links = []\n",
    "ap_text = []\n",
    "ap_titles = []\n",
    "ap_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get homepage article links\n",
    "for link in ap_tags:\n",
    "    link = link.get('href')\n",
    "    link = \"https://apnews.com\" + link\n",
    "    ap_links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep for article content\n",
    "for link in ap_links:\n",
    "    ap_article_request = requests.get(link)\n",
    "    ap_article = ap_article_request.content\n",
    "    ap_article_soup = BeautifulSoup(ap_article, 'html.parser')\n",
    "    \n",
    "    # article titles\n",
    "    title = ap_article_soup.find_all('meta')[14]\n",
    "    title = title['content']\n",
    "    ap_titles.append(title)\n",
    "    \n",
    "    # article date\n",
    "    date = ap_article_soup.find_all('meta')[24]\n",
    "    date = date['content']\n",
    "    ap_dates.append(date)\n",
    "    \n",
    "    # article content: <div class=\"Article\" data-key=Article.\n",
    "    body = ap_article_soup.find_all('div')\n",
    "    x = body[0].find_all('p')\n",
    "\n",
    "    # combine paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        paragraph = paragraph.replace('\\n',\"\")\n",
    "        list_paragraphs.append(paragraph)\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "    ap_text.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AP</td>\n",
       "      <td>2020-03-10T04:15:12Z</td>\n",
       "      <td>https://apnews.com/8d90a37e5e5b177d08424fd14a2...</td>\n",
       "      <td>'Odd' quirk raises delegate stakes in Tuesday'...</td>\n",
       "      <td>WASHINGTON (AP) — A quirk in how delegates are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>2020-03-10T04:35:05Z</td>\n",
       "      <td>https://apnews.com/5b4fa2256d232ca24b2f93fff31...</td>\n",
       "      <td>Michigan primary could make or break Sanders' ...</td>\n",
       "      <td>DETROIT (AP) — Bernie Sanders proved his 2016 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AP</td>\n",
       "      <td>2020-03-10T00:05:20Z</td>\n",
       "      <td>https://apnews.com/a5e4261f40050e07ad3b6b9eb04...</td>\n",
       "      <td>Trump talks down virus as his properties face ...</td>\n",
       "      <td>NEW YORK (AP) — One of President Donald Trump’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AP</td>\n",
       "      <td>2020-03-09T16:09:06Z</td>\n",
       "      <td>https://apnews.com/2e8a815a031e8da37075feec466...</td>\n",
       "      <td>US begins troop withdrawal from Afghanistan, o...</td>\n",
       "      <td>WASHINGTON (AP) — American troops have begun l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AP</td>\n",
       "      <td>2020-03-10T04:41:42Z</td>\n",
       "      <td>https://apnews.com/896611803373610849fe8602b64...</td>\n",
       "      <td>Trump plans payroll tax relief in response to ...</td>\n",
       "      <td>WASHINGTON (AP) — President Donald Trump says ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publisher                  date  \\\n",
       "0        AP  2020-03-10T04:15:12Z   \n",
       "1        AP  2020-03-10T04:35:05Z   \n",
       "2        AP  2020-03-10T00:05:20Z   \n",
       "3        AP  2020-03-09T16:09:06Z   \n",
       "4        AP  2020-03-10T04:41:42Z   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://apnews.com/8d90a37e5e5b177d08424fd14a2...   \n",
       "1  https://apnews.com/5b4fa2256d232ca24b2f93fff31...   \n",
       "2  https://apnews.com/a5e4261f40050e07ad3b6b9eb04...   \n",
       "3  https://apnews.com/2e8a815a031e8da37075feec466...   \n",
       "4  https://apnews.com/896611803373610849fe8602b64...   \n",
       "\n",
       "                                       article_title  \\\n",
       "0  'Odd' quirk raises delegate stakes in Tuesday'...   \n",
       "1  Michigan primary could make or break Sanders' ...   \n",
       "2  Trump talks down virus as his properties face ...   \n",
       "3  US begins troop withdrawal from Afghanistan, o...   \n",
       "4  Trump plans payroll tax relief in response to ...   \n",
       "\n",
       "                                        article_text  \n",
       "0  WASHINGTON (AP) — A quirk in how delegates are...  \n",
       "1  DETROIT (AP) — Bernie Sanders proved his 2016 ...  \n",
       "2  NEW YORK (AP) — One of President Donald Trump’...  \n",
       "3  WASHINGTON (AP) — American troops have begun l...  \n",
       "4  WASHINGTON (AP) — President Donald Trump says ...  "
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join ap data\n",
    "ap_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'AP',\n",
    "    'date': ap_dates,\n",
    "    'link': ap_links,\n",
    "    'article_title': ap_titles,\n",
    "    'article_text': ap_text \n",
    "})\n",
    "\n",
    "ap_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in old data\n",
    "old_ap_data = pd.read_csv('data/ap_data.csv')\n",
    "\n",
    "# append new data\n",
    "ap_data = old_ap_data.append(ap_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "ap_data.to_csv(\"data/ap_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "# see number of articles\n",
    "print(len(ap_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. New York Times - Liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "nyt_request = requests.get('https://www.nytimes.com/section/politics')\n",
    "nyt_homepage = nyt_request.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup \n",
    "nyt_soup = BeautifulSoup(nyt_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homepage URLs\n",
    "nyt_tags_home = nyt_soup.find_all('h2', class_=\"css-l2vidh e4e4i5l1\")\n",
    "\n",
    "# archive URLs\n",
    "nyt_tags_archive = nyt_soup.find_all('div', class_='css-1l4spti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup \n",
    "nyt_links = []\n",
    "nyt_titles = []\n",
    "nyt_dates = []\n",
    "nyt_contents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homepage articles\n",
    "for n in np.arange(0, len(nyt_tags_home)):\n",
    "\n",
    "    # get article link\n",
    "    link = nyt_tags_home[n].find('a')['href']\n",
    "    link = \"https://www.nytimes.com\" + link\n",
    "    nyt_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = nyt_tags_home[n].find('a').get_text()\n",
    "    nyt_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.time.attrs['datetime']\n",
    "    date = date[:-15]\n",
    "    nyt_dates.append(date)\n",
    "    \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', {'class':['css-53u6y8', 'css-1fanzo5']})\n",
    "    final_article = \" \".join([item.text for item in body])\n",
    "        \n",
    "    nyt_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# archive articles\n",
    "for n in np.arange(0, len(nyt_tags_archive)):\n",
    "\n",
    "    # get article link\n",
    "    link = nyt_tags_archive[n].find('a')['href']\n",
    "    link = \"https://www.nytimes.com\" + link\n",
    "    nyt_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = nyt_tags_archive[n].find('a').get_text()\n",
    "    nyt_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.time.attrs['datetime']\n",
    "    date = date[:-15]\n",
    "    nyt_dates.append(date)\n",
    "        \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', attrs = {'class':['css-53u6y8', 'css-1fanzo5 StoryBodyCompanionColumn']})\n",
    "    final_article = \" \".join([item.text for item in body])\n",
    "        \n",
    "    nyt_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembling data\n",
    "nyt_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'new_york_times',\n",
    "    'date': nyt_dates,\n",
    "    'link': nyt_links,\n",
    "    'article_title': nyt_titles,\n",
    "    'article_text': nyt_contents \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WEST PALM BEACH, Fla. — President Trump on Fri...</td>\n",
       "      <td>Trump Names Mark Meadows Chief of Staff, Ousti...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.nytimes.com/2020/03/06/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>President Trump claimed again on Friday that a...</td>\n",
       "      <td>With Test Kits in Short Supply, Health Officia...</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>https://www.nytimes.com/2020/03/06/health/test...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bernie Sanders was several takes into a video ...</td>\n",
       "      <td>The Bernie Sanders Personality Test</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>https://www.nytimes.com/2020/03/06/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joseph R. Biden Jr.’s campaign organization in...</td>\n",
       "      <td>Joe Biden Has Had Flimsy Organization. It Hasn...</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>https://www.nytimes.com/2020/03/06/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FLINT, Mich. — Cornel West pleaded with his “o...</td>\n",
       "      <td>Sanders Is Behind With Black Voters. He Didn’t...</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>https://www.nytimes.com/2020/03/08/us/politics...</td>\n",
       "      <td>new_york_times</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_text  \\\n",
       "0  WEST PALM BEACH, Fla. — President Trump on Fri...   \n",
       "1  President Trump claimed again on Friday that a...   \n",
       "2  Bernie Sanders was several takes into a video ...   \n",
       "3  Joseph R. Biden Jr.’s campaign organization in...   \n",
       "4  FLINT, Mich. — Cornel West pleaded with his “o...   \n",
       "\n",
       "                                       article_title        date  \\\n",
       "0  Trump Names Mark Meadows Chief of Staff, Ousti...  2020-03-07   \n",
       "1  With Test Kits in Short Supply, Health Officia...  2020-03-07   \n",
       "2                The Bernie Sanders Personality Test  2020-03-06   \n",
       "3  Joe Biden Has Had Flimsy Organization. It Hasn...  2020-03-06   \n",
       "4  Sanders Is Behind With Black Voters. He Didn’t...  2020-03-08   \n",
       "\n",
       "                                                link       publisher  \n",
       "0  https://www.nytimes.com/2020/03/06/us/politics...  new_york_times  \n",
       "1  https://www.nytimes.com/2020/03/06/health/test...  new_york_times  \n",
       "2  https://www.nytimes.com/2020/03/06/us/politics...  new_york_times  \n",
       "3  https://www.nytimes.com/2020/03/06/us/politics...  new_york_times  \n",
       "4  https://www.nytimes.com/2020/03/08/us/politics...  new_york_times  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it looks nice\n",
    "nyt_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entries in old data: 14\n",
      "total number of entries in new data: 14\n"
     ]
    }
   ],
   "source": [
    "# read in old data\n",
    "old_nyt_data = pd.read_csv('data/nyt_data.csv')\n",
    "num_old = len(old_nyt_data)\n",
    "\n",
    "# append new data\n",
    "nyt_data = old_nyt_data.append(nyt_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "nyt_data.to_csv(\"data/nyt_data.csv\", index = False)\n",
    "num_now = len(nyt_data)\n",
    "\n",
    "print(\"number of entries in old data: {}\".format(num_old))\n",
    "print(\"total number of entries in new data: {}\".format(num_now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Buzzfeed - Very Liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the HTML content using requests and save into a variable\n",
    "buzz_request = requests.get('https://www.buzzfeednews.com/section/politics')\n",
    "buzz_homepage = buzz_request.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup \n",
    "buzz_soup = BeautifulSoup(buzz_homepage, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate article URLs\n",
    "buzz_tags = buzz_soup.find_all('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "number_of_articles = min(len(buzz_tags), 30)\n",
    "\n",
    "# get article titles, content, and links\n",
    "buzz_links = []\n",
    "buzz_titles = []\n",
    "buzz_dates = []\n",
    "buzz_contents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get article titles, content, and links\n",
    "for n in np.arange(0, number_of_articles):\n",
    "\n",
    "    # get article link\n",
    "    link = buzz_tags[n].find('a')['href']\n",
    "    buzz_links.append(link)\n",
    "    \n",
    "    # get article title\n",
    "    title = buzz_tags[n].find('a').get_text()\n",
    "    buzz_titles.append(title)\n",
    "    \n",
    "    # prep article content\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    \n",
    "    # get publication datetime\n",
    "    date = soup_article.find_all('div', class_=\"news-article-header__timestamps\")    \n",
    "    date = \" \".join([item.text for item in date]).replace('\\n', '')\n",
    "    buzz_dates.append(date)\n",
    "    \n",
    "    # get article content\n",
    "    body = soup_article.find_all('div', attrs={'data-module':'subbuzz-text'})\n",
    "    article = \" \".join([item.text for item in body]).replace('\\n', '')\n",
    "    final_article = re.sub(r' {[^}]*}', '', article)\n",
    "        \n",
    "    buzz_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembling data\n",
    "buzz_data = pd.DataFrame.from_dict({\n",
    "    'publisher': 'buzzfeed',\n",
    "    'date': buzz_dates,\n",
    "    'link': buzz_links,\n",
    "    'article_title': buzz_titles,\n",
    "    'article_text': buzz_contents \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FLINT, Mich. — It was a rare move for the...</td>\n",
       "      <td>Bernie Sanders Scrapped A Planned Speech On Ra...</td>\n",
       "      <td>Posted on March 7, 2020, at 10:18 ...</td>\n",
       "      <td>https://www.buzzfeednews.com/article/rubycrame...</td>\n",
       "      <td>buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW DELHI — A tweet by Tulsi Gabbard, the...</td>\n",
       "      <td>Tulsi Gabbard's Tweet About Anti-Hinduism In T...</td>\n",
       "      <td>Posted on March 6, 2020, at 12:11 ...</td>\n",
       "      <td>https://www.buzzfeednews.com/article/nishitajh...</td>\n",
       "      <td>buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The image began to circulate again on Thu...</td>\n",
       "      <td>What Happened To The Women Of 2020? Fears Of “...</td>\n",
       "      <td>Posted on March 5, 2020, at 6:35 p...</td>\n",
       "      <td>https://www.buzzfeednews.com/article/mollyhens...</td>\n",
       "      <td>buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON — Congress will send President...</td>\n",
       "      <td>Congress Quickly Passed An $8.3 Billion Spendi...</td>\n",
       "      <td>Posted on March 5, 2020, at 2:23 p...</td>\n",
       "      <td>https://www.buzzfeednews.com/article/kadiagoba...</td>\n",
       "      <td>buzzfeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Three weeks after ending his presidential...</td>\n",
       "      <td>Andrew Yang Is Launching A Political Group To ...</td>\n",
       "      <td>Posted on March 5, 2020, at 11:11 ...</td>\n",
       "      <td>https://www.buzzfeednews.com/article/rubycrame...</td>\n",
       "      <td>buzzfeed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_text  \\\n",
       "0       FLINT, Mich. — It was a rare move for the...   \n",
       "1       NEW DELHI — A tweet by Tulsi Gabbard, the...   \n",
       "2       The image began to circulate again on Thu...   \n",
       "3       WASHINGTON — Congress will send President...   \n",
       "4       Three weeks after ending his presidential...   \n",
       "\n",
       "                                       article_title  \\\n",
       "0  Bernie Sanders Scrapped A Planned Speech On Ra...   \n",
       "1  Tulsi Gabbard's Tweet About Anti-Hinduism In T...   \n",
       "2  What Happened To The Women Of 2020? Fears Of “...   \n",
       "3  Congress Quickly Passed An $8.3 Billion Spendi...   \n",
       "4  Andrew Yang Is Launching A Political Group To ...   \n",
       "\n",
       "                                                date  \\\n",
       "0              Posted on March 7, 2020, at 10:18 ...   \n",
       "1              Posted on March 6, 2020, at 12:11 ...   \n",
       "2              Posted on March 5, 2020, at 6:35 p...   \n",
       "3              Posted on March 5, 2020, at 2:23 p...   \n",
       "4              Posted on March 5, 2020, at 11:11 ...   \n",
       "\n",
       "                                                link publisher  \n",
       "0  https://www.buzzfeednews.com/article/rubycrame...  buzzfeed  \n",
       "1  https://www.buzzfeednews.com/article/nishitajh...  buzzfeed  \n",
       "2  https://www.buzzfeednews.com/article/mollyhens...  buzzfeed  \n",
       "3  https://www.buzzfeednews.com/article/kadiagoba...  buzzfeed  \n",
       "4  https://www.buzzfeednews.com/article/rubycrame...  buzzfeed  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buzz_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of entries in new data: 30\n"
     ]
    }
   ],
   "source": [
    "# read in old data\n",
    "old_buzz_data = pd.read_csv('data/buzzfeed_data.csv')\n",
    "num_old = len(old_buzz_data)\n",
    "\n",
    "# append new data\n",
    "buzz_data = old_buzz_data.append(buzz_data).drop_duplicates()\n",
    "\n",
    "# save new .csv\n",
    "buzz_data.to_csv(\"data/buzzfeed_data.csv\", index = False)\n",
    "num_now = len(buzz_data)\n",
    "\n",
    "#print(\"number of entries in old data: {}\".format(num_old))\n",
    "print(\"total number of entries in new data: {}\".format(num_now))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
